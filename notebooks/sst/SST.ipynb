{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/probabll/dgm4nlp/blob/master/notebooks/sst/SST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Udt3kHMdWvYe"
   },
   "source": [
    "We will need to import some helper code, so we need to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8eXUCRiWvYi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYhItDYMZi6a"
   },
   "source": [
    "# Colab\n",
    "\n",
    "We will need to download some data for this notebook, so if you are using [colab](https://colab.research.google.com), set the `using_colab` flag below to `True` in order to clone our [github repo](https://github.com/probabll/dgm4nlp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_shCMftIx1rW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t     img\t  nn\t       README.md  sstutil.py\r\n",
      "evaluate.py  __init__.py  plotting.py  SST.ipynb  util.py\r\n"
     ]
    }
   ],
   "source": [
    "using_colab = False\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-fFME2OW22i"
   },
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "  !rm -fr dgm4nlp sst\n",
    "  !git clone https://github.com/probabll/dgm4nlp.git\n",
    "  !cp -R dgm4nlp/notebooks/sst ./  \n",
    "  !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_7NCZlZacNu"
   },
   "source": [
    "Now we can start our lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9mH-rUhWvYq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# CPU should be fine for this lab\n",
    "device = torch.device('cpu')  \n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okMoxTJ9bWjc"
   },
   "source": [
    "# Sentiment Classification \n",
    "\n",
    "\n",
    "We are going to augment a sentiment classifier with a layer of discrete latent variables which will help us improve the model's interpretability. But first, let's quickly review the baseline task.\n",
    "\n",
    "\n",
    "In sentiment classification, we have some text input $x = \\langle x_1, \\ldots, x_n \\rangle$, e.g. a sentence or short paragraph, which expresses a certain sentiment $y$, i.e. one of $K$ classes, towards a subject (e.g. a film or a product). \n",
    "\n",
    "\n",
    "\n",
    "We can learn a sentiment classifier by learning a categorical distribution over classes for a given input:\n",
    "\n",
    "\\begin{align}\n",
    "Y|x &\\sim \\text{Cat}(f(x; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where the Categorical pmf is $\\text{Cat}(y|\\pi) = \\pi_y$.\n",
    "\n",
    "A categorical distribution over $K$ classes is parameterised by a $K$-dimensional probability vector, here we use a neural network $f$ to map from the input to this probability vector. Technically we say *a neural network parameterise our model*, that is, it computes the parameters of our categorical observation model. The figure below is a graphical depiction of the model: circled nodes are random variables (a shaded node is an observed variable), uncircled nodes are deterministic, a plate indicates multiple draws.\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/classifier.png\"  height=\"100\">\n",
    "\n",
    "The neural network (NN) $f(\\cdot; \\theta)$ has parameters of its own, i.e. the weights of the various architecture blocks used, which we denoted generically by $\\theta$.\n",
    "\n",
    "Suppose we have a dataset $\\mathcal D = \\{(x^{(1)}, y^{(1)}), \\ldots, (x^{(N)}, y^{(N)})\\}$ containing $N$ i.i.d. observations. Then we can use the log-likelihood function \n",
    "\\begin{align}\n",
    "\\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{N} \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\\n",
    "&= \\sum_{k=1}^{N} \\log \\text{Cat}(y^{(k)}|f(x^{(k)}; \\theta))\n",
    "\\end{align}\n",
    " to estimate $\\theta$ by maximisation:\n",
    " \\begin{align}\n",
    " \\theta^\\star = \\arg\\max_{\\theta \\in \\Theta} \\mathcal L(\\theta|\\mathcal D) ~ .\n",
    " \\end{align}\n",
    " \n",
    "\n",
    "We can use stochastic gradient-ascent to find a local optimum of $\\mathcal L(\\theta|\\mathcal D)$, which only requires a gradient estimate:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{|\\mathcal D|} \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\ \n",
    "&= \\sum_{k=1}^{|\\mathcal D|} \\frac{1}{N} N \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta)  \\\\\n",
    "&= \\mathbb E_{\\mathcal U(1/N)} \\left[ N \\nabla_\\theta  \\log P(y^{(K)}|x^{(K)}, \\theta) \\right]  \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{N}{M} \\sum_{m=1}^M \\nabla_\\theta  \\log P(y^{(k_m)}|x^{(k_m)}, \\theta) \\\\\n",
    "&\\text{where }K_m \\sim \\mathcal U(1/N)\n",
    "\\end{align}\n",
    "\n",
    "This is a Monte Carlo (MC) estimate of the gradient computed on $M$ data points selected uniformly at random from $\\mathcal D$.\n",
    "\n",
    "For as long as $f$ remains differentiable wrt to its inputs and parameters, we can rely on automatic differentiation to obtain gradient estimates.\n",
    "\n",
    "In what follows we show how to design $f$ and how to extend this basic model to a latent-variable model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LUjyO-39zan"
   },
   "source": [
    "## Data\n",
    "\n",
    "We provide you some code to load the data (see `sst.sstutil.examplereader`). Play with the snippet below and inspect a few training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4z8Bt5no9z6w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Examples\n",
      "First dev example: Example(tokens=['And', 'if', 'you', \"'re\", 'not', 'nearly', 'moved', 'to', 'tears', 'by', 'a', 'couple', 'of', 'scenes', ',', 'you', \"'ve\", 'got', 'ice', 'water', 'in', 'your', 'veins', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], token_labels=[2, 2, 2, 2, 1, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['And', 'if', 'you', \"'re\", 'not', 'nearly', 'moved', 'to', 'tears', 'by', 'a', 'couple', 'of', 'scenes', ',', 'you', \"'ve\", 'got', 'ice', 'water', 'in', 'your', 'veins', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "from sst.sstutil import examplereader, Vocabulary, load_glove    \n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader('data/sst/train.txt'))\n",
    "dev_data = list(examplereader('data/sst/dev.txt'))\n",
    "test_data = list(examplereader('data/sst/test.txt'))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Examples')\n",
    "example = dev_data[2]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lB2lEsNuWvYx"
   },
   "source": [
    "## Architecture\n",
    "\n",
    "\n",
    "The function $f$ conditions on a high-dimensional input (i.e. text), so we need to convert it to continuous real vectors. This is the job an *encoder*. \n",
    "\n",
    "**Embedding Layer**\n",
    "\n",
    "The first step is to convert the words in $x$ to vectors, which in this lab we will do with a pre-trained embedding layer (we will use GloVe).\n",
    "\n",
    "We will denote the embedding of the $i$th word of the input by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf x_i = \\text{glove}(x_i)\n",
    "\\end{equation}\n",
    "\n",
    "**Encoder Layer**\n",
    "\n",
    "In this lab, an encoder takes a sequence of input vectors $\\mathbf x_1^n$, each $I$-dimensional, and produces a sequence of output vectors $\\mathbf t_1^n$, each $O$-dimensional and a summary vector $\\mathbf h \\in \\mathbb R^O$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf t_1^n, \\mathbf h = \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}})\n",
    "\\end{equation}\n",
    "\n",
    "where we use $\\theta_{\\text{enc}}$ to denote the subset of parameters in $\\theta$ that are specific to this encoder block. \n",
    "\n",
    "*Remark:* in practice for a correct batched implementation, our encoders also take a mask matrix and a vector of lengths.\n",
    "\n",
    "Examples of encoding functions can be a feed-forward NN (with an aggregator based on sum or average/max pooling) or a recurrent NN (e.g. an LSTM/GRU). Other architectures are also possible.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "From our summary vector $\\mathbf h$, we need to parameterise a categorical distribution over $K$ classes, thus we use\n",
    "\n",
    "\\begin{align}\n",
    "f(x; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where $\\text{dense}_K$ is a dense layer with $K=5$ outputs and $\\theta_{\\text{output}}$ corresponds to its parameters (weight matrix and bias vector). Note that we need to use the softmax activation function in order to guarantee that the output of $f$ is a normalised probability vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kc15Nv2i41cq"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "To leave an indication of the shape of tensors in the code, we use the following convention\n",
    "\n",
    "```python\n",
    "[B, T, D]\n",
    "```\n",
    "\n",
    "where `B` stands for `batch_size`, `T` stands for `time` (or rather *maximum sequence length*), and `D` is the size of the representation.\n",
    "\n",
    "\n",
    "Consider the following abstract Encoder class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwEPXT2MWvYz",
    "tags": [
     "encoders"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    An Encoder for us is a function that\n",
    "      1. transforms a sequence of I-dimensional vectors into a sequence of O-dimensional vectors\n",
    "      2. summarises a sequence of I-dimensional vectors into one O-dimensional vector\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        \"\"\"\n",
    "        The input is a batch-first tensor of token ids. Here is an example:\n",
    "        \n",
    "        Example of inputs (though rather than words, we have word ids):\n",
    "            INPUTS                     MASK       LENGTHS\n",
    "            [the nice cat -PAD-]    -> [1 1 1 0]  [3]\n",
    "            [the nice dog running]  -> [1 1 1 1]  [4]\n",
    "            \n",
    "        Note that:\n",
    "              mask =  inputs == 1\n",
    "              lengths = mask.sum(dim=-1)\n",
    "        \n",
    "        :param inputs: [B, T, I]\n",
    "        :param mask: [B, T]\n",
    "        :param lengths: [B]\n",
    "        :returns: [B, T, O], [B, O]\n",
    "            where the first tensor is the transformed input\n",
    "            and the second tensor is a summary of all inputs\n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WA5wmkcRg9Am"
   },
   "source": [
    "Let's start easy, implement a *bag of words* encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-9hLQ0lF5SG"
   },
   "outputs": [],
   "source": [
    "class BagOfWordsEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This encoder does not transform the input sequence, \n",
    "     and its summary output is just a sum.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BagOfWordsEncoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        return inputs, torch.sum(inputs * mask[:, :, None].type(inputs.type()), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS7x0hLrUXfN"
   },
   "source": [
    "You can also consider implementing\n",
    "\n",
    "* a feed-forward encoder with average pooling\n",
    "* and a biLSTM encoder\n",
    "\n",
    "but these are certainly optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpOGFpK_Uo0-"
   },
   "outputs": [],
   "source": [
    "class FFEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    A typical feed-forward NN with tanh hidden activations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size, \n",
    "                 activation=None, \n",
    "                 hidden_sizes=[], \n",
    "                 aggregator='avg',\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "        :param output_size: int\n",
    "        :param hidden_sizes: list of integers (dimensionality of hidden layers)\n",
    "        :param aggregator: 'sum' or 'avg'\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super(FFEncoder, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(input_size, output_size), nn.Dropout(dropout), nn.Tanh())\n",
    "        self.aggr = aggregator\n",
    "        \n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return: \n",
    "            outputs [B, T, O]\n",
    "            sum/avg pooling [B, O]\n",
    "        \"\"\"\n",
    "        inp = x * mask[:, :, None].type(x.type())\n",
    "        out = self.net(inp)\n",
    "        if self.aggr == 'avg':\n",
    "            aggr = torch.mean(out, dim=1)\n",
    "        elif self.aggr == 'sum':\n",
    "            aggr = torch.sum(out, dim=1)\n",
    "        else:\n",
    "            raise ValueError('bad aggr')\n",
    "        return out, aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxQ5djZ_VAvK"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxQ5djZ_VAvK"
   },
   "outputs": [],
   "source": [
    "class LSTMEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This module encodes a sequence using a bidirectional LSTM\n",
    "     it returns the final state\n",
    "     and the hidden states at each time step. Note: we concatenate representations\n",
    "     from the two directions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, \n",
    "                 hidden_size: int = 200,\n",
    "                 batch_first: bool = True,\n",
    "                 bidirectional: bool = True):\n",
    "        \"\"\"\n",
    "        :param in_features:\n",
    "        :param hidden_size:\n",
    "        :param batch_first:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.net = nn.LSTM(in_features, hidden_size, batch_first=batch_first, bidirectional=bidirectional)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Encode sentence x\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return:\n",
    "            outputs [B, T, O]\n",
    "            final state [B, O]\n",
    "        \"\"\"\n",
    "        inp = x * mask[:, :, None].type(x.type())\n",
    "        pack = pack_padded_sequence(input=inp, lengths=lengths, batch_first=self.batch_first)\n",
    "        output, (h_n, c_n) = self.net(pack)\n",
    "        output, _ = pad_packed_sequence(output, batch_first=self.batch_first)\n",
    "        \n",
    "        if self.net.bidirectional:\n",
    "            hidden = torch.cat([h[-2], h[-1]], dim=-1)\n",
    "        else:\n",
    "            hidden = h[-1]\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_zz5zIyVkSh"
   },
   "source": [
    "Here is some helper code to select and return an encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59ZU6JddVjMV"
   },
   "outputs": [],
   "source": [
    "def get_encoder(layer, in_features, hidden_size, bidirectional=True):\n",
    "    \"\"\"Returns the requested layer.\"\"\"\n",
    "\n",
    "    # TODO: make pass and average layers\n",
    "    if layer == \"bow\":\n",
    "        return BagOfWordsEncoder()\n",
    "    elif layer == 'ff':\n",
    "        return FFEncoder(\n",
    "            in_features, \n",
    "            2 * hidden_size,   # for convenience\n",
    "            hidden_sizes=[hidden_size], \n",
    "            aggregator='avg')\n",
    "    elif layer == \"lstm\":\n",
    "        return LSTMEncoder(\n",
    "            in_features, \n",
    "            hidden_size,\n",
    "            bidirectional=bidirectional)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY8LZiMN5CHW"
   },
   "source": [
    "# Sentiment Classification with Latent Rationale\n",
    "\n",
    "A latent rationale is a compact and informative fragment of the input based on which a NN classifier makes its decisions. [Lei et al (2016)](http://aclweb.org/anthology/D16-1011) proposed to induce such rationales along with a regression model for multi-aspect sentiment analsysis, their model is trained via REINFORCE on a dataset of beer reviews.\n",
    "\n",
    "*Remark:* the model we will develop here can be seen as a probabilistic version of their model. The rest of this notebook focus on our own probabilitisc view of the model.\n",
    "\n",
    "The picture below depicts our latent-variable model for rationale extraction:\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/rationale.png\"  height=\"200\">\n",
    "\n",
    "where we augment the model with a collection of latent variables $z = \\langle z_1, \\ldots, z_n\\rangle$ where $z_i$ is a binary latent variable. Each latent variable $z_i$ regulates whether or not the input $x_i$ is available to the classifier.  We use $x \\odot z$ to denote the selected words, which, in the terminology of Lei et al, is a latent rationale.\n",
    "\n",
    "Again the classifier parameterises a Categorical distribution over $K=5$ outcomes, though this time it can encode only a selection of the input:\n",
    "\n",
    "\\begin{align}\n",
    "    Z_i & \\sim \\text{Bern}(p_1) \\\\\n",
    "    Y|z,x &\\sim \\text{Cat}(f(x \\odot z; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where we have a shared and fixed Bernoulli prior (with parameter $p_1$) for all $n$ latent variables.\n",
    "\n",
    "\n",
    "Here is an example design for $f$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= z_i \\, \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}}) \\\\\n",
    "f(x \\odot z; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "* $z_i$ either leaves $\\mathbf x_i$ unchanged or turns it into a vector of zeros;\n",
    "* the encoder only sees features from selected inputs, i.e. $x_i$ for which $z_i = 1$;\n",
    "* $\\text{dense}_K$ is a linear layer with $K=5$ outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDHNxLHMWvY-"
   },
   "source": [
    "## Prior\n",
    "\n",
    "\n",
    "Our prior is a Bernoulli with fixed parameter $0 < p_1 < 1$:\n",
    "\n",
    "\\begin{align}\n",
    "Z_i & \\sim \\text{Bern}(p_1)\n",
    "\\end{align}\n",
    "\n",
    "whose pmf is $\\text{Bern}(z_i|p_1) = p_1^{z_i}\\times (1-p_1)^{1-z_i}$.\n",
    "\n",
    "As we will be using Bernoulli priors and posteriors, it is a good idea to implement a Bernoulli class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCBcHnTsOuDr"
   },
   "outputs": [],
   "source": [
    "class Bernoulli:\n",
    "    \"\"\"\n",
    "    This class encapsulates a collection of Bernoulli distributions. \n",
    "    Each Bernoulli is uniquely specified by p_1, where\n",
    "        Bernoulli(X=x|p_1) = pow(p_1, x) * pow(1 - p_1, 1 - x)\n",
    "    is the Bernoulli probability mass function (pmf). \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits=None, probs=None):\n",
    "        \"\"\"\n",
    "        We can specify a Bernoulli distribution via a logit or a probability. \n",
    "         You need to specify at least one, and if you specify both, beware that\n",
    "         in this implementation logits will be used.\n",
    "         \n",
    "        Recall that: probs = sigmoid(logits).\n",
    "         \n",
    "        :param logits: a tensor of logits (a logit is defined as log (p_1/p_0))\n",
    "            where p_0 = 1 - p_1\n",
    "        :param probs: a tensor of probabilities, each in (0, 1)\n",
    "        \n",
    "        \"\"\"        \n",
    "        self.dist = torch.distributions.Bernoulli(probs=probs, logits=logits)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a single sample with the same shape as the parameters\"\"\"\n",
    "        return self.dist.sample()\n",
    "    \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        Assess the log probability of a sample. \n",
    "        \n",
    "        :param x: either a single sample (0 or 1) or a tensor of samples with the same shape as the parameters.\n",
    "        :returns: tensor with log probabilities with the same shape as parameters\n",
    "            (if the input is a single sample we broadcast it to the shape of the parameters)\n",
    "        \"\"\"\n",
    "        return self.dist.log_prob(x)\n",
    "    \n",
    "    def kl(self, other: 'Bernoulli'):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between two Bernoulli distributions (from self to other).\n",
    "        \n",
    "        :return: KL[self||other] with same shape parameters\n",
    "        \"\"\"\n",
    "        probs = self.dist.probs\n",
    "        other_probs = other.dist.probs.type(probs.type())\n",
    "        part1 = probs * (torch.log(probs + 1e-20) - torch.log(other_probs + 1e-20))\n",
    "        part2 = (1 - probs) * (torch.log(1 - probs + 1e-20) - torch.log(1 - other_probs + 1e-20))\n",
    "        return torch.sum(part1 + part2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0yfkCZlWvZP"
   },
   "source": [
    "## Classifier\n",
    "\n",
    "The classifier encodes only a selection of the input, which we denote $x \\odot z$, and parameterises a Categorical distribution over $5$ outcomes (sentiment levels).\n",
    "\n",
    "Thus let's implement a Categorical distribution (we will only need to be able to assess its lgo pmf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-6JLDnBQcdg"
   },
   "outputs": [],
   "source": [
    "class Categorical:\n",
    "    def __init__(self, log_probs):\n",
    "        # [B, K]: class probs\n",
    "        self.log_probs = log_probs\n",
    "        self.dist = torch.distributions.Categorical(logits=log_probs)\n",
    "        \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [B] integers (targets)\n",
    "        :returns: [B] scalars (log probabilities)\n",
    "        \"\"\"\n",
    "        return self.dist.log_prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdrM_YRI8xBF"
   },
   "source": [
    "and a classifier architecture:\n",
    "\n",
    "* implement the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz7GaKbgRCd8"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder takes an input text (and rationale z) and computes p(y|x,z)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:        nn.Embedding = None,\n",
    "                 hidden_size:  int = 200,\n",
    "                 output_size:  int = 1,\n",
    "                 dropout:      float = 0.1,\n",
    "                 layer:        str = \"pass\",\n",
    "                 ):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        # Here we embed the words\n",
    "        self.embed_layer = nn.Sequential(\n",
    "            embed\n",
    "            # , nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        # and here we predict categorical parameters\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        :params x: [B, T, I] word representations\n",
    "        :params mask: [B, T] indicates valid positions\n",
    "        :params z: [B, T] binary selectors\n",
    "        :returns: one Categorical distribution per instance in the batch\n",
    "          each conditioning only on x_i for which z_i = 1\n",
    "        \"\"\"\n",
    "        embed = self.embed_layer(x)\n",
    "        embed = embed * z[:, :, None].type(embed.type())\n",
    "        lengths = torch.sum(mask, dim=1).long()\n",
    "        enc_out, aggr = self.enc_layer(embed, z, lengths)\n",
    "        log_probs = self.output_layer(aggr)\n",
    "        return Categorical(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2waCCBF9MaH"
   },
   "source": [
    "## Inference\n",
    "\n",
    "\n",
    "Computing the log-likelihood of an observation requires marginalising over assignments of $z$:\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x,\\theta,p_1) &= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 P(z|p_1)\\times P(y|x,z, \\theta) \\\\\n",
    "&= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 \\left( \\prod_{i=1}^n \\text{Bern}(z_i|p_1)\\right) \\times \\text{Cat}(y|f(x \\odot z; \\theta)) \n",
    "\\end{align}\n",
    "\n",
    "This is clearly intractable: there are $2^n$ possible assignments to $z$ and because the classifier conditions on all latent selectors, there's no way to simplify the expression.\n",
    "\n",
    "We will avoid computing this intractable marginal by instead employing an independently parameterised inference model.\n",
    "This inference model $Q(z|x, y, \\lambda)$ is an approximation to the true postrerior $P(z|x, y, \\theta, p_1)$, and we use $\\lambda$ to denote its parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jcVdYTg8Wun"
   },
   "source": [
    "We make a *mean field* assumption, whereby we model latent variables independently given the input:\n",
    "\\begin{align}\n",
    "Q(z|x, y, \\lambda) \n",
    "    &= \\prod_{i=1}^{n} Q(z_i|x; \\lambda) \\\\\n",
    "    &= \\prod_{i=1}^{n} \\text{Bern}(z_i|g_i(x; \\lambda)) \n",
    "\\end{align}\n",
    "\n",
    "where $g(x; \\lambda)$ is a NN that maps from $x = \\langle x_1, \\ldots, x_n\\rangle$ to $n$ Bernoulli parameters, each of which, is a probability value (thus $0 < g_i(x; \\lambda) < 1$).\n",
    "\n",
    "Note that though we could condition on $y$ for approximate posterior inference, we are opportunistically leaving it out. This way, $Q$ is directly available at test time for making predictions. The figure below is a graphical depiction of the inference model (we show a dashed arrow from $y$ to $z$ to remind you that in principle the label is also available).\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/inference.png\"  height=\"200\">\n",
    "\n",
    "Here is an example design for $g$:\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\lambda_{\\text{enc}}) \\\\\n",
    "g_i(x; \\lambda) &= \\sigma(\\text{dense}_1(\\mathbf t_i; \\lambda_{\\text{output}}))\n",
    "\\end{align}\n",
    "where\n",
    "* $\\text{glove}$ is a pre-trained embedding function;\n",
    "* $\\text{dense}_1$ is a dense layer with a single output;\n",
    "* and $\\sigma(\\cdot)$ is the sigmoid function, necessary to parameterise a Bernoulli distribution.\n",
    "\n",
    "From now on we will write $Q(z|x, \\lambda)$, that is, without $y.\n",
    "\n",
    "Here we implement this product of Bernoulli distributions:\n",
    "\n",
    "* implement $g$ in the constructor \n",
    "* and the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLxfcAbuSiFo"
   },
   "outputs": [],
   "source": [
    "class ProductOfBernoullis(nn.Module):\n",
    "    \"\"\"\n",
    "    This is an inference network that parameterises independent Bernoulli distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:       nn.Embedding,\n",
    "                 hidden_size: int = 200,\n",
    "                 layer:       str = \"bow\"\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param embed: an embedding layer\n",
    "        :param hidden_suze: hidden size for transformed inputs\n",
    "        :param layer: 'bow' for BoW encoding\n",
    "          you may alternatively implement and 'lstm' option\n",
    "          which uses a biLSTM to transform the inputs         \n",
    "        \"\"\"\n",
    "\n",
    "        super(ProductOfBernoullis, self).__init__()\n",
    "        self.layer = layer\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "\n",
    "        self.embed_layer = nn.Sequential(embed)\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "        self.logit_layer = nn.Linear(enc_size, 1, bias=True)\n",
    "        \n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        It takes a tensor of tokens (integers)\n",
    "         and predicts a Bernoulli distribution for each position.\n",
    "        \n",
    "        :param x: [B, T]\n",
    "        :param mask: [B, T]\n",
    "        :returns: Bernoulli\n",
    "        \"\"\"\n",
    "\n",
    "        lengths = torch.sum(mask.long(), dim=1)\n",
    "        embed = self.embed_layer(x)\n",
    "        h, aggr = self.enc_layer(embed, mask, lengths)\n",
    "        \n",
    "        logits = self.logit_layer(h).squeeze(-1)\n",
    "        \n",
    "        return Bernoulli(logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcCu7vkKWvZX"
   },
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "In variational inference, our objective is to maximise the *evidence lowerbound* (ELBO):\n",
    "\n",
    "\\begin{align}\n",
    "\\log P(y|x) &\\ge \\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\text{KL}(Q(z|x, y, \\lambda) || P(z|p_1)) \\\\\n",
    "\\text{ELBO}&\\overset{\\text{MF}}{=}\\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1)) \n",
    "\\end{align}\n",
    "\n",
    "where the *mean field* assumption we made implies that the KL term is simply a sum of KL divergences from a Bernoulli posterior to a Bernoulli prior.\n",
    "\n",
    "Note that the ELBO remains intractable, namely, solving the expectation in closed form still requires $2^n$ evaluations of the classifier network. Though unlike the true posterior $P(z|x,y, \\lambda)$, the approximation $Q(z|x,\\lambda)$ is tractable (it does not require an intractable normalisation) and can be used to obtain gradient estimates based on samples.\n",
    "\n",
    "### Gradient of the classifier network\n",
    "\n",
    "For the classifier, we encounter no problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\text{ELBO} &=\\nabla_\\theta\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\underbrace{\\nabla_\\theta \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{\\color{blue}{0}}  \\\\\n",
    "&=\\sum_{z} Q(z|x, \\lambda)\\nabla_\\theta\\log P(y|x,z,\\theta) \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\theta\\log P(y|x,z,\\theta) \\right] \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S \\nabla_\\theta \\log P(y|x, z^{(s)}, \\theta) \n",
    "\\end{align}\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$.\n",
    "\n",
    "\n",
    "### Gradient of the inference network\n",
    "\n",
    "For the inference model, we have to use the *score function estimator* (a.k.a. REINFORCE):\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\text{ELBO} &=\\nabla_\\lambda\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\nabla_\\lambda \\underbrace{\\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{ \\color{blue}{\\text{tractable} }}  \\\\\n",
    "&=\\sum_{z} \\nabla_\\lambda Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&=\\sum_{z}  \\underbrace{Q(z|x, \\lambda) \\nabla_\\lambda \\log Q(z|x, \\lambda)}_{\\nabla_\\lambda Q(z|x, \\lambda)} \\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(y|x,z,\\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) \\right] - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\left(\\frac{1}{S} \\sum_{s=1}^S  \\log P(y|x, z^{(s)}, \\theta) \\nabla_\\lambda \\log Q(z^{(s)}|x, \\lambda)  \\right) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))  \n",
    "\\end{align}\n",
    "\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cdfkOYdC0LQ"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Let's implement the model and the loss (negative ELBO). We work with the notion of a *surrogate loss*, that is, a computation node whose gradients wrt to parameters are equivalent to the gradients we need.\n",
    "\n",
    "For a given sample $z \\sim Q(z|x, \\lambda)$, the following is a single-sample surrogate loss:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal S(\\theta, \\lambda|x, y) = \\log P(y|x, z, \\theta) + \\color{red}{\\text{detach}(\\log P(y|x, z, \\theta) )}\\log Q(z|x, \\lambda) - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|\\phi))\n",
    "\\end{align}\n",
    "where we introduce an auxiliary function such that\n",
    "\\begin{align}\n",
    "\\text{detach}(f(\\alpha))  &= h(\\alpha) \\\\\n",
    "\\nabla_\\beta \\text{detach}(h(\\alpha))  &= 0 \n",
    "\\end{align}\n",
    "or in words, *detach* does not alter the forward call of its argument function $h$, but it alters $h$'s backward call by setting gradients to zero.\n",
    "\n",
    "Show that it's gradients wrt $\\theta$ and $\\lambda$ are exactly what we need:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FednEChaX6WI"
   },
   "source": [
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal S(\\theta, \\lambda|x, y) = \\color{red}{?}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\mathcal S(\\theta, \\lambda|x, y) = \\color{red}{?}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaUMKDShx9T0"
   },
   "source": [
    "Implement the forward pass and loss below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cnwwk-7tfR02"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Classifier model:\n",
    "        Z_i ~ Bern(p_1) for i in 1..n\n",
    "        Y|x,z ~ Cat(f([x_i if z_i 1 else 0 for i in 1..n ]))\n",
    "    \n",
    "    Inference model:\n",
    "        Z_i|x ~ Bern(b_i) for i in 1..n\n",
    "            where b_i = g_i(x)\n",
    "    \n",
    "    Objective:\n",
    "        Single-sample MC estimate of ELBO\n",
    "    \n",
    "    Loss: \n",
    "        Surrogate loss\n",
    "\n",
    "    Consists of:\n",
    "        - a product of Bernoulli distributions inference network\n",
    "        - a classifier network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab:       object = None,\n",
    "                 vocab_size:  int = 0,\n",
    "                 emb_size:    int = 200,\n",
    "                 hidden_size: int = 200,\n",
    "                 num_classes: int = 5,\n",
    "                 prior_p1:    float = 0.3,                 \n",
    "                 det_prior: bool = True,\n",
    "                 beta_shape:  list = [0.6, 0.6],\n",
    "                 dropout:     float = 0.1,\n",
    "                 layer_cls:   str = 'bow',\n",
    "                 layer_inf:   str = 'bow',\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param vocab: Vocabulary\n",
    "        :param vocab_size: necessary for embedding layer\n",
    "        :param emb_size: dimensionality of embedding layer\n",
    "        :param hidden_size: dimensionality of hidden layers\n",
    "        :param num_classes: number of classes\n",
    "        :param prior_p1: (scalar) prior Bernoulli parameter\n",
    "        :param det_prior: (boolean) whether the prior parameter is deterministic\n",
    "        :param beta_shape: (pair of positive scalars) \n",
    "            when the prior parameter is stochastic\n",
    "            it is sampled from a Beta distribution (ignore this at first)\n",
    "        :param dropout: (scalar) dropout rate\n",
    "        :param layer_cls: type of encoder for classification\n",
    "        :param layer_inf: type of encoder for inference\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.embed = embed = nn.Embedding(vocab_size, emb_size, padding_idx=1)\n",
    "\n",
    "        self.cls_net = Classifier(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size, \n",
    "            output_size=num_classes,\n",
    "            dropout=dropout, \n",
    "            layer=layer_cls)\n",
    "        \n",
    "        self.inference_net = ProductOfBernoullis(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size,\n",
    "            layer=layer_inf)\n",
    "        \n",
    "        self._prior_p1 = prior_p1\n",
    "        self._det_prior = det_prior\n",
    "        self._beta_shape = beta_shape\n",
    "        \n",
    "    def get_prior_p1(self, p_min=0.001, p_max=0.999):\n",
    "        \"\"\"Return the prior Bernoulli parameter\"\"\"\n",
    "        if self._det_prior:\n",
    "            return self._prior_p1\n",
    "        else:\n",
    "            a, b = self._beta_shape\n",
    "            prior_p1 = np.random.beta(a, b)\n",
    "            prior_p1 = max(prior_p1, p_min)\n",
    "            prior_p1 = min(prior_p1, p_max)\n",
    "        return prior_p1\n",
    "\n",
    "    def predict(self, py: Categorical, **kwargs):\n",
    "        \"\"\"\n",
    "        Predict deterministically using argmax.\n",
    "        :param py: B Categorical distributions (one per instance in batch)\n",
    "        :return: predictions\n",
    "            [B] sentiment levels\n",
    "        \"\"\"\n",
    "        assert not self.training, \"should be in eval mode for prediction\"\n",
    "        return py.log_probs.argmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Generate a sequence z with inference model, \n",
    "         then predict with rationale xz, that is, x masked by z.\n",
    "\n",
    "        :param x: [B, T] documents        \n",
    "        :param mask: [B, T] indicates valid positions vs padded positions\n",
    "        :return: \n",
    "            Categorical distributions P(y|x, z)\n",
    "            Bernoulli distributions Q(z|x)\n",
    "            Single sample z ~ Q(z|x) used for the conditional P(y|x, z)\n",
    "        \"\"\"\n",
    "        mask = (x != 1)\n",
    "        qz = self.inference_net(x, mask)\n",
    "        z = qz.sample()\n",
    "        z = torch.where(mask.byte(), z, torch.zeros_like(z))\n",
    "        py = self.cls_net(x, mask, z)\n",
    "        return py, qz, z\n",
    "\n",
    "    def get_loss(self,                   \n",
    "                 y, \n",
    "                 py: Categorical,\n",
    "                 qz: Bernoulli, \n",
    "                 z, \n",
    "                 mask,\n",
    "                 iter_i=0, \n",
    "                 # you may ignore the rest of the arguments for the time being\n",
    "                 #  leave them as they are\n",
    "                 kl_weight=1.0,\n",
    "                 min_kl=0.0,\n",
    "                 ll_mean=0.,\n",
    "                 ll_std=1.,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        This computes the loss for the whole model.\n",
    "\n",
    "        :param y: target labels [B]\n",
    "        :param py: conditionals P(y|x, z)\n",
    "        :param qz: approximate posteriors Q(z|x)\n",
    "        :param z: sample of binary selectors [B, T]\n",
    "        :param mask: indicates valid positions [B, T]\n",
    "        :param iter_i: indicates the iteration\n",
    "        :param kl_weight: (scalar) multiplies the KL term\n",
    "        :param min_kl: (scalar) sets a minimum for the KL (aka free bits)\n",
    "        :param ll_mean: (scalar) running average of reward\n",
    "        :param ll_std: (scalar) running standard deviation of reward\n",
    "        :return: loss (torch node), terms (dict)\n",
    "        \n",
    "            terms is an OrderedDict that holds the scalar items involved in the loss\n",
    "            e.g. `terms['ll'] = ll.item()` is the log-likelihood term\n",
    "            \n",
    "            Consider tracking the following:\n",
    "            Single-sample ELBO: terms['elbo']\n",
    "            Log-Likelihood log P(y|x,z): terms['ll']\n",
    "            KL: terms['kl']\n",
    "            Score function surrogate log P(y|z, x) log Q(z|x): terms['sf']            \n",
    "            Rate of selected words: terms['selected']\n",
    "        \"\"\"\n",
    "\n",
    "        lengths = mask.sum(1).float()\n",
    "        _prior = Bernoulli(probs=self.get_prior_p1())\n",
    "        \n",
    "        kl = qz.kl(_prior)\n",
    "        kl = torch.where(mask.byte(), kl, torch.zeros_like(kl))\n",
    "        kl = kl.sum(dim=-1)\n",
    "        \n",
    "        py_xz = py.log_pmf(y)\n",
    "        \n",
    "        qz_x = qz.log_pmf(z)\n",
    "        qz_x = torch.where(mask.byte(), qz_x, torch.zeros_like(qz_x))\n",
    "        qz_x = qz_x.sum(dim=-1)\n",
    "        \n",
    "        detached = py_xz.detach()\n",
    "        \n",
    "        score_function = detached * qz_x\n",
    "    \n",
    "        reconstruction_loss = py_xz + score_function\n",
    "        elbo = torch.sum(reconstruction_loss - kl)\n",
    "        \n",
    "        terms = {\n",
    "            'elbo' : float(elbo),\n",
    "            'll' : float(py_xz.sum()),\n",
    "            'kl' : float(kl.sum()),\n",
    "            'sf' : float(score_function.sum()),\n",
    "            'selected' : float((z.sum(1) / lengths).mean())\n",
    "        }\n",
    "        return -elbo, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNQDXTpqWvZa"
   },
   "outputs": [],
   "source": [
    "# This will be used later for maintaining runnin averages of quantites like \n",
    "#  terms in the ELBO\n",
    "from collections import deque\n",
    "\n",
    "class MovingStats:\n",
    "    \n",
    "    def __init__(self, memory=-1):\n",
    "        self.data = deque([])\n",
    "        self.memory = memory\n",
    "        \n",
    "    def append(self, value):\n",
    "        if self.memory != 0:\n",
    "            if self.memory > 0 and len(self.data) == self.memory:\n",
    "                self.data.popleft()\n",
    "            self.data.append(value)\n",
    "        \n",
    "    def mean(self):\n",
    "        if len(self.data):\n",
    "            return np.mean([x for x in self.data])\n",
    "        else:\n",
    "            return 0.\n",
    "    \n",
    "    def std(self):\n",
    "        return np.std(self.data) if len(self.data) > 1 else 1.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "081YSfU9WvZc"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Pc80gseWvZd"
   },
   "outputs": [],
   "source": [
    "# some helper code for mini batching\n",
    "#  this will take care of annoying things such as \n",
    "#  sorting training instances by length (necessary for pytorch's LSTM, for example)\n",
    "from sst.util import make_kv_string, get_minibatch, prepare_minibatch, print_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WVr97kilIRV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Configuration\n",
      "training_path        : data/sst/train.txt\n",
      "dev_path             : data/sst/dev.txt\n",
      "test_path            : data/sst/test.txt\n",
      "word_vectors         : data/sst/glove.840B.300d.filtered.txt\n",
      "prior_p1             :        0.3\n",
      "beta_a               :        0.6\n",
      "beta_b               :        0.6\n",
      "det_prior            :          1\n",
      "num_epochs           :        201\n",
      "print_every          :        100\n",
      "eval_every           :         -1\n",
      "batch_size           :        100\n",
      "eval_batch_size      :        100\n",
      "subphrases           :          0\n",
      "min_phrase_length    :          2\n",
      "lowercase            :          1\n",
      "fix_emb              :          1\n",
      "embed_size           :        300\n",
      "hidden_size          :        150\n",
      "num_layers           :          1\n",
      "dropout              :        0.5\n",
      "layer_inf            : bow       \n",
      "layer_cls            : bow       \n",
      "save_path            : data/results\n",
      "baseline_memory      :       1000\n",
      "min_kl               :        0.0\n",
      "kl_weight            :        1.0\n",
      "kl_inc               :      1e-05\n",
      "lr                   :     0.0002\n",
      "weight_decay         :      1e-05\n",
      "lr_decay             :        0.5\n",
      "patience             :          5\n",
      "cooldown             :          5\n",
      "threshold            :     0.0001\n",
      "min_lr               :      1e-05\n",
      "max_grad_norm        :        5.0\n",
      "Set eval_every to 85\n",
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Example\n",
      "First dev example: Example(tokens=['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "# We will use Adam\n",
    "from torch.optim import Adam\n",
    "# and a couple of tricks to reduce learning rate on plateau\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# here is some helper code to evaluate your model\n",
    "from sst.evaluate import evaluate\n",
    "\n",
    "\n",
    "cfg = dict()\n",
    "\n",
    "# Data\n",
    "cfg['training_path'] = \"data/sst/train.txt\"\n",
    "cfg['dev_path'] = \"data/sst/dev.txt\"\n",
    "cfg['test_path'] = \"data/sst/test.txt\"\n",
    "cfg['word_vectors'] = 'data/sst/glove.840B.300d.filtered.txt'\n",
    "# Model\n",
    "cfg['prior_p1'] = 0.3\n",
    "cfg['beta_a'] = 0.6\n",
    "cfg['beta_b'] = 0.6\n",
    "cfg['det_prior'] = True\n",
    "# Architecture\n",
    "cfg['num_epochs'] = 201\n",
    "cfg['print_every'] = 100\n",
    "cfg['eval_every'] = -1\n",
    "cfg['batch_size'] = 100\n",
    "cfg['eval_batch_size'] = 100\n",
    "cfg['subphrases'] = False\n",
    "cfg['min_phrase_length'] = 2\n",
    "cfg['lowercase'] = True\n",
    "cfg['fix_emb'] = True\n",
    "cfg['embed_size'] = 300\n",
    "cfg['hidden_size'] = 150\n",
    "cfg['num_layers'] = 1\n",
    "cfg['dropout'] = 0.5\n",
    "cfg['layer_inf'] = 'bow'\n",
    "cfg['layer_cls'] = 'bow'\n",
    "cfg['save_path'] = 'data/results'\n",
    "cfg['baseline_memory'] = 1000\n",
    "cfg['min_kl'] = 0.  # use more than 0 to enable free bits\n",
    "cfg['kl_weight'] = 1.  # start from zero to enable annealing\n",
    "cfg['kl_inc'] = 0.00001\n",
    "# Optimiser (leave as is)\n",
    "cfg['lr'] = 0.0002\n",
    "cfg['weight_decay'] = 1e-5\n",
    "cfg['lr_decay'] = 0.5\n",
    "cfg['patience'] = 5\n",
    "cfg['cooldown'] = 5\n",
    "cfg['threshold'] = 1e-4\n",
    "cfg['min_lr'] = 1e-5\n",
    "cfg['max_grad_norm'] = 5.\n",
    "\n",
    "\n",
    "print('# Configuration')\n",
    "for k, v in cfg.items():\n",
    "    print(\"{:20} : {:10}\".format(k, v))\n",
    "\n",
    "\n",
    "iters_per_epoch = len(train_data) // cfg[\"batch_size\"]\n",
    "\n",
    "if cfg[\"eval_every\"] == -1:\n",
    "    eval_every = iters_per_epoch\n",
    "    print(\"Set eval_every to {}\".format(iters_per_epoch))\n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader(\n",
    "    cfg['training_path'],\n",
    "    lower=cfg['lowercase'], \n",
    "    subphrases=cfg['subphrases'],\n",
    "    min_length=cfg['min_phrase_length']))\n",
    "dev_data = list(examplereader(cfg['dev_path'], lower=cfg['lowercase']))\n",
    "test_data = list(examplereader(cfg['test_path'], lower=cfg['lowercase']))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Example')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PMqtVj0WvZf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    # Create a vocabulary object to map str <-> int\n",
    "    vocab = Vocabulary()  # populated by load_glove\n",
    "    glove_path = cfg[\"word_vectors\"]\n",
    "    vectors = load_glove(glove_path, vocab)\n",
    "\n",
    "    # You may consider using tensorboardX\n",
    "    # writer = SummaryWriter(log_dir=cfg[\"save_path\"])\n",
    "\n",
    "    # Map the sentiment labels 0-4 to a more readable form (and the opposite)\n",
    "    i2t = [\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"]\n",
    "    t2i = OrderedDict({p: i for p, i in zip(i2t, range(len(i2t)))})\n",
    "\n",
    "\n",
    "    print('\\n# Constructing model')\n",
    "    model = Model(\n",
    "        vocab_size=len(vocab.w2i), \n",
    "        emb_size=cfg[\"embed_size\"],\n",
    "        hidden_size=cfg[\"hidden_size\"], \n",
    "        num_classes=len(t2i),\n",
    "        prior_p1=cfg['prior_p1'],\n",
    "        det_prior=cfg['det_prior'],\n",
    "        beta_shape=[cfg['beta_a'], cfg['beta_b']],\n",
    "        vocab=vocab, \n",
    "        dropout=cfg[\"dropout\"], \n",
    "        layer_cls=cfg[\"layer_cls\"],\n",
    "        layer_inf=cfg[\"layer_inf\"])\n",
    "\n",
    "    print('\\n# Loading embeddings')\n",
    "    with torch.no_grad():\n",
    "        model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
    "        if cfg[\"fix_emb\"]:\n",
    "            print(\"fixed word embeddings\")\n",
    "            model.embed.weight.requires_grad = False\n",
    "        model.embed.weight[1] = 0.  # padding zero\n",
    "\n",
    "        \n",
    "    # Congigure optimiser\n",
    "    optimizer = Adam(model.parameters(), lr=cfg[\"lr\"],\n",
    "                     weight_decay=cfg[\"weight_decay\"])\n",
    "    # and learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=cfg[\"lr_decay\"], patience=cfg[\"patience\"],\n",
    "        verbose=True, cooldown=cfg[\"cooldown\"], threshold=cfg[\"threshold\"],\n",
    "        min_lr=cfg[\"min_lr\"])\n",
    "\n",
    "    # Prepare a few auxiliary variables\n",
    "    iter_i = 0\n",
    "    train_loss = 0.\n",
    "    print_num = 0\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    best_eval = 1.0e9\n",
    "    best_iter = 0\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Some debugging info\n",
    "    print(model)\n",
    "    print_parameters(model)\n",
    "\n",
    "    batch_size = cfg['batch_size']\n",
    "    eval_batch_size = cfg['eval_batch_size']\n",
    "    print_every = cfg['print_every']\n",
    "\n",
    "    # Parameters of tricks to better optimise the ELBO \n",
    "    kl_inc = cfg['kl_inc']\n",
    "    kl_weight = cfg['kl_weight']\n",
    "    min_kl = cfg['min_kl']\n",
    "    # Running estimates for baselines\n",
    "    ll_moving_stats = MovingStats(cfg['baseline_memory'])\n",
    "    \n",
    "    epoch = 0\n",
    "    while epoch < cfg[\"num_epochs\"]:  # when we run out of examples, shuffle and continue\n",
    "        for batch in get_minibatch(train_data, batch_size=batch_size, shuffle=True):\n",
    "\n",
    "            epoch = iter_i // iters_per_epoch\n",
    "            if epoch > cfg['num_epochs']:\n",
    "                break\n",
    "\n",
    "            # forward pass\n",
    "            model.train()\n",
    "            x, y, _ = prepare_minibatch(batch, model.vocab, device=device)\n",
    "            \n",
    "            mask = (x != 1)\n",
    "            py, qz, z = model(x)\n",
    "\n",
    "            # \"KL annealing\"\n",
    "            kl_weight += kl_inc\n",
    "            if kl_weight > 1.:\n",
    "                kl_weight = 1.0\n",
    "                \n",
    "            loss, terms = model.get_loss(\n",
    "                y,\n",
    "                py=py, \n",
    "                qz=qz,\n",
    "                z=z,\n",
    "                mask=mask, \n",
    "                kl_weight=kl_weight,\n",
    "                min_kl=min_kl,\n",
    "                ll_mean=ll_moving_stats.mean(),\n",
    "                ll_std=ll_moving_stats.std(),\n",
    "                iter_i=iter_i)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # keep an running estimate of the reward (log P(y|x,z))\n",
    "            ll_moving_stats.append(terms['ll'])\n",
    "\n",
    "            # backward pass\n",
    "            model.zero_grad()  # erase previous gradients\n",
    "\n",
    "            loss.backward()  # compute new gradients\n",
    "\n",
    "            # gradient clipping generally helps\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['max_grad_norm'])\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            print_num += 1\n",
    "            iter_i += 1\n",
    "\n",
    "            # print info\n",
    "            if iter_i % print_every == 0:\n",
    "\n",
    "                train_loss = train_loss / print_every\n",
    "\n",
    "                print_str = make_kv_string(terms)\n",
    "                print(\"Epoch %r Iter %r loss=%.4f %s\" %\n",
    "                      (epoch, iter_i, train_loss, print_str))\n",
    "                losses.append(train_loss)\n",
    "                print_num = 0\n",
    "                train_loss = 0.\n",
    "\n",
    "            # evaluate\n",
    "            if iter_i % eval_every == 0:\n",
    "\n",
    "                dev_eval, rationales = evaluate(\n",
    "                    model, dev_data, \n",
    "                    batch_size=eval_batch_size, \n",
    "                    device=device,\n",
    "                    cfg=cfg, iter_i=iter_i)\n",
    "                accuracies.append(dev_eval[\"acc\"])\n",
    "\n",
    "                print(\"\\n# epoch %r iter %r: dev %s\" % (\n",
    "                    epoch, iter_i, make_kv_string(dev_eval)))\n",
    "                \n",
    "                for exid in range(3):\n",
    "                    print(' dev%d [gold=%d,pred=%d]:' % (exid, dev_data[exid].label, rationales[exid][1]),  \n",
    "                          ' '.join(rationales[exid][0]))\n",
    "                print()\n",
    "\n",
    "                # adjust learning rate\n",
    "                scheduler.step(dev_eval[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5uYKcw-WvZl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Constructing model\n",
      "Classifier #params: 1505\n",
      "ProductOfBernoullis #params: 301\n",
      "\n",
      "# Loading embeddings\n",
      "fixed word embeddings\n",
      "Model(\n",
      "  (embed): Embedding(20727, 300, padding_idx=1)\n",
      "  (cls_net): Classifier(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "    )\n",
      "    (enc_layer): BagOfWordsEncoder()\n",
      "    (output_layer): Sequential(\n",
      "      (0): Dropout(p=0.5)\n",
      "      (1): Linear(in_features=300, out_features=5, bias=True)\n",
      "      (2): LogSoftmax()\n",
      "    )\n",
      "  )\n",
      "  (inference_net): ProductOfBernoullis(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "    )\n",
      "    (enc_layer): BagOfWordsEncoder()\n",
      "    (logit_layer): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "embed.weight             [20727, 300] requires_grad=False\n",
      "cls_net.output_layer.1.weight [5, 300]     requires_grad=True\n",
      "cls_net.output_layer.1.bias [5]          requires_grad=True\n",
      "inference_net.logit_layer.weight [1, 300]     requires_grad=True\n",
      "inference_net.logit_layer.bias [1]          requires_grad=True\n",
      "\n",
      "Total parameters: 6219906\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 0 iter 85: dev loss 561936.0551 elbo -561936.0551 ll -162.8165 kl 563911.2617 sf 2138.0320 selected 0.4052 acc 0.2688\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with lovely **performances** by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one **goes** **unindicted** here , which **is** **probably** **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved **to** **tears** by **a** couple **of** scenes , you **'ve** **got** ice water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 1 Iter 100 loss=637857.9912 elbo -525097.5625 ll -192.3525 kl 527599.1875 sf 2693.9480 selected 0.4050\n",
      "\n",
      "# epoch 1 iter 170: dev loss 480825.5294 elbo -480825.5294 ll -157.2931 kl 482629.9848 sf 1961.7543 selected 0.3540 acc 0.2725\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here , which is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not nearly moved to **tears** **by** a **couple** **of** scenes , you 've **got** ice water **in** **your** veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 2 Iter 200 loss=505378.2835 elbo -423415.3125 ll -169.7749 kl 425555.6250 sf 2310.1016 selected 0.3604\n",
      "\n",
      "# epoch 2 iter 255: dev loss 444961.4925 elbo -444961.4925 ll -152.3688 kl 446669.9959 sf 1860.8932 selected 0.3334 acc 0.3115\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with lovely performances **by** **buy** **and** **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** **not** **nearly** **moved** to **tears** by a **couple** of **scenes** , you 've got ice **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 3 Iter 300 loss=455621.9088 elbo -417529.6875 ll -157.9100 kl 419277.5312 sf 1905.7751 selected 0.3626\n",
      "\n",
      "# epoch 3 iter 340: dev loss 418459.5025 elbo -418459.5025 ll -152.7614 kl 420138.4521 sf 1831.6864 selected 0.3252 acc 0.3161\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with lovely **performances** by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here , **which** **is** probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're **not** **nearly** **moved** to **tears** **by** a **couple** of scenes , you 've got **ice** water **in** **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 4 Iter 400 loss=430516.8484 elbo -361710.4688 ll -150.9002 kl 363380.0000 sf 1820.4006 selected 0.3315\n",
      "\n",
      "# epoch 4 iter 425: dev loss 395276.4429 elbo -395276.4429 ll -152.0635 kl 396947.8007 sf 1823.4201 selected 0.3187 acc 0.3106\n",
      " dev0 [gold=3,pred=3]: it **'s** a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** which is **probably** for the **best** .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're **not** nearly **moved** **to** tears **by** a couple **of** scenes , you **'ve** **got** ice water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 5 Iter 500 loss=402897.3135 elbo -318423.5312 ll -152.3523 kl 320006.3438 sf 1735.0770 selected 0.3305\n",
      "\n",
      "# epoch 5 iter 510: dev loss 374056.3202 elbo -374056.3202 ll -151.4073 kl 375724.8013 sf 1819.8910 selected 0.3188 acc 0.3134\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** **lovely** film with lovely performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes **unindicted** here , which is probably for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to tears **by** **a** **couple** of scenes , **you** 've **got** **ice** water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 6 iter 595: dev loss 354242.0580 elbo -354242.0580 ll -149.5038 kl 355880.0973 sf 1787.5229 selected 0.3155 acc 0.3460\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** **film** with lovely performances by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** **here** , which is **probably** **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved to tears by a **couple** **of** scenes **,** **you** **'ve** **got** ice water **in** **your** veins **.**\n",
      "\n",
      "Epoch 7 Iter 600 loss=378061.9172 elbo -375168.2812 ll -147.1547 kl 376620.4375 sf 1599.2373 selected 0.3465\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 7 iter 680: dev loss 335568.2447 elbo -335568.2447 ll -150.1100 kl 337199.9569 sf 1781.8349 selected 0.3088 acc 0.3361\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely **film** **with** lovely performances by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** **is** probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not **nearly** moved **to** tears by a couple of scenes , you **'ve** got **ice** water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 8 Iter 700 loss=346394.5555 elbo -257710.0312 ll -158.8669 kl 259487.0312 sf 1935.8606 selected 0.3249\n",
      "\n",
      "# epoch 8 iter 765: dev loss 317851.6752 elbo -317851.6752 ll -149.5612 kl 319496.8416 sf 1794.7388 selected 0.3107 acc 0.3333\n",
      " dev0 [gold=3,pred=3]: it **'s** a **lovely** film with lovely **performances** by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which is **probably** for **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: **and** if you **'re** not nearly **moved** to **tears** by a couple of scenes , **you** 've **got** ice **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 9 Iter 800 loss=333161.9823 elbo -392723.3438 ll -155.2308 kl 394492.2812 sf 1924.1793 selected 0.3325\n",
      "\n",
      "# epoch 9 iter 850: dev loss 301002.8696 elbo -301002.8696 ll -148.9358 kl 302621.6300 sf 1767.6940 selected 0.3088 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely **film** **with** lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here **,** which is **probably** for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're not nearly **moved** **to** **tears** by a couple of scenes , you 've got **ice** water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 10 Iter 900 loss=303064.7431 elbo -287739.9688 ll -160.4990 kl 289730.5312 sf 2151.0200 selected 0.3217\n",
      "\n",
      "# epoch 10 iter 935: dev loss 284906.4140 elbo -284906.4140 ll -147.5239 kl 286512.6579 sf 1753.7635 selected 0.3104 acc 0.3460\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with **lovely** performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** **here** **,** **which** is probably **for** the **best** .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly moved **to** tears by a couple of scenes , you 've **got** **ice** water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 11 Iter 1000 loss=290602.0835 elbo -332390.2812 ll -145.9973 kl 333925.0938 sf 1680.8417 selected 0.2916\n",
      "\n",
      "# epoch 11 iter 1020: dev loss 269481.9942 elbo -269481.9942 ll -149.0600 kl 271091.1929 sf 1758.2620 selected 0.3031 acc 0.3361\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film with lovely performances **by** **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , which is **probably** **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to **tears** by a couple of **scenes** , you 've got ice **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Iter 1100 loss=273726.8939 elbo -297653.5000 ll -147.6443 kl 299251.8750 sf 1745.9844 selected 0.3253\n",
      "\n",
      "# epoch 12 iter 1105: dev loss 254670.3798 elbo -254670.3798 ll -149.6053 kl 256301.7713 sf 1781.0008 selected 0.3070 acc 0.3351\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** **film** with **lovely** performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=4]: no one **goes** **unindicted** **here** , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly **moved** **to** **tears** **by** **a** couple of **scenes** **,** you 've got **ice** water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 13 iter 1190: dev loss 240475.4957 elbo -240475.4957 ll -148.7579 kl 242086.0568 sf 1759.3120 selected 0.3048 acc 0.3342\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** **lovely** film with lovely **performances** by **buy** and **accorsi** **.**\n",
      " dev1 [gold=2,pred=1]: **no** one **goes** unindicted here , **which** is **probably** for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're not nearly moved **to** tears by **a** **couple** of scenes **,** you **'ve** got ice **water** in your veins **.**\n",
      "\n",
      "Epoch 14 Iter 1200 loss=254108.0795 elbo -264586.3125 ll -146.2851 kl 266208.8750 sf 1768.8651 selected 0.3099\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 14 iter 1275: dev loss 226810.8999 elbo -226810.8999 ll -148.9062 kl 228427.0918 sf 1765.0917 selected 0.3074 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** **film** with **lovely** performances by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** 're **not** nearly **moved** **to** tears **by** a couple **of** **scenes** , **you** 've got ice **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 15 Iter 1300 loss=234581.6787 elbo -239658.5469 ll -157.0726 kl 241477.2188 sf 1975.7657 selected 0.2905\n",
      "\n",
      "# epoch 15 iter 1360: dev loss 213663.9777 elbo -213663.9777 ll -147.7913 kl 215272.2183 sf 1756.0350 selected 0.3124 acc 0.3351\n",
      " dev0 [gold=3,pred=3]: **it** **'s** **a** **lovely** film **with** **lovely** performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , which is probably for **the** **best** .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you **'re** not **nearly** moved **to** tears by a **couple** of **scenes** , you 've got **ice** water **in** **your** **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 16 Iter 1400 loss=220001.5338 elbo -212749.2031 ll -159.4571 kl 214373.1875 sf 1783.4233 selected 0.3093\n",
      "\n",
      "# epoch 16 iter 1445: dev loss 201003.2518 elbo -201003.2518 ll -148.2458 kl 202609.5181 sf 1754.4978 selected 0.3052 acc 0.3270\n",
      " dev0 [gold=3,pred=4]: it **'s** a **lovely** film with **lovely** **performances** **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** which is probably for **the** **best** .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** **to** tears by a couple of scenes **,** **you** **'ve** **got** ice water **in** **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 17 Iter 1500 loss=206990.7585 elbo -156768.2812 ll -146.1234 kl 158309.8750 sf 1687.7308 selected 0.3089\n",
      "\n",
      "# epoch 17 iter 1530: dev loss 188803.5525 elbo -188803.5525 ll -147.8904 kl 190412.4855 sf 1756.8204 selected 0.3078 acc 0.3460\n",
      " dev0 [gold=3,pred=4]: **it** **'s** **a** lovely film with **lovely** performances **by** buy and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which **is** probably **for** the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** **you** **'re** not nearly **moved** to tears by **a** **couple** of **scenes** , you **'ve** **got** **ice** water in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 18 Iter 1600 loss=187758.6938 elbo -167189.5938 ll -153.9101 kl 168863.3594 sf 1827.6608 selected 0.2892\n",
      "\n",
      "# epoch 18 iter 1615: dev loss 177069.8260 elbo -177069.8260 ll -146.1706 kl 178660.7200 sf 1737.0625 selected 0.3053 acc 0.3542\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely **film** **with** **lovely** performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , **which** is probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not nearly **moved** **to** **tears** by a couple of **scenes** **,** **you** 've got ice water **in** your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 19 Iter 1700 loss=181294.0923 elbo -183685.8438 ll -149.0579 kl 185214.9375 sf 1678.1213 selected 0.3135\n",
      "\n",
      "# epoch 19 iter 1700: dev loss 165758.4194 elbo -165758.4194 ll -145.3048 kl 167347.2691 sf 1734.1498 selected 0.3095 acc 0.3515\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film **with** lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , which is probably **for** **the** best **.**\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not **nearly** moved to tears by a couple of scenes , you **'ve** got ice water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 20 iter 1785: dev loss 154862.9056 elbo -154862.9056 ll -147.0567 kl 156446.7553 sf 1730.9110 selected 0.3026 acc 0.3597\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film **with** lovely **performances** **by** **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** **'re** not nearly moved to tears by **a** couple of scenes , **you** **'ve** **got** **ice** **water** in **your** veins .\n",
      "\n",
      "Epoch 21 Iter 1800 loss=162861.9326 elbo -195047.7812 ll -141.7697 kl 196610.1250 sf 1704.1105 selected 0.2941\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 21 iter 1870: dev loss 144361.4724 elbo -144361.4724 ll -147.5847 kl 145960.9085 sf 1747.0290 selected 0.3071 acc 0.3515\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film **with** **lovely** **performances** **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here **,** which is **probably** for **the** best **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to tears by **a** couple of scenes , **you** 've got **ice** **water** in your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 22 Iter 1900 loss=148102.4927 elbo -142451.9844 ll -145.6914 kl 144024.9062 sf 1718.5741 selected 0.2991\n",
      "\n",
      "# epoch 22 iter 1955: dev loss 134291.7038 elbo -134291.7038 ll -147.1280 kl 135876.5002 sf 1731.9302 selected 0.3003 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** with lovely **performances** **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here **,** which is probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to **tears** by **a** couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 23 Iter 2000 loss=137785.4069 elbo -137243.2812 ll -138.9400 kl 138714.3281 sf 1609.9637 selected 0.2967\n",
      "\n",
      "# epoch 23 iter 2040: dev loss 124585.1835 elbo -124585.1835 ll -148.5328 kl 126188.0038 sf 1751.3522 selected 0.3005 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely **film** with **lovely** **performances** by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** **which** is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved **to** tears **by** a couple of scenes , you 've **got** **ice** water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 24 Iter 2100 loss=128102.4940 elbo -131679.0000 ll -143.0062 kl 133103.4844 sf 1567.4639 selected 0.3020\n",
      "\n",
      "# epoch 24 iter 2125: dev loss 115263.0808 elbo -115263.0808 ll -148.0314 kl 116884.9576 sf 1769.9032 selected 0.3069 acc 0.3388\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film **with** lovely performances by **buy** and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one **goes** **unindicted** here **,** which is **probably** for the **best** .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved to tears by **a** couple of scenes , you 've got **ice** **water** in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 25 Iter 2200 loss=115463.4061 elbo -140863.5625 ll -143.7750 kl 142434.9531 sf 1715.1697 selected 0.2916\n",
      "\n",
      "# epoch 25 iter 2210: dev loss 106365.7980 elbo -106365.7980 ll -147.2382 kl 107965.6590 sf 1747.0983 selected 0.3061 acc 0.3297\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** , which is probably for the best **.**\n",
      " dev2 [gold=3,pred=4]: and if **you** **'re** not nearly **moved** to tears **by** a couple **of** scenes , **you** **'ve** got ice **water** **in** your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "\n",
      "# epoch 26 iter 2295: dev loss 97831.2883 elbo -97831.2883 ll -146.2430 kl 99426.6781 sf 1741.6333 selected 0.3063 acc 0.3678\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** lovely film with lovely performances by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** **,** **which** **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: **and** if you **'re** **not** nearly **moved** **to** tears **by** a couple **of** scenes , you 've got **ice** water **in** your **veins** .\n",
      "\n",
      "Epoch 27 Iter 2300 loss=106874.1469 elbo -135163.9062 ll -147.0287 kl 136944.8594 sf 1927.9816 selected 0.3060\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 27 iter 2380: dev loss 89660.3753 elbo -89660.3753 ll -147.7597 kl 91263.1179 sf 1750.4989 selected 0.3045 acc 0.3397\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely **performances** **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** unindicted **here** **,** which is **probably** **for** the **best** .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** **nearly** moved **to** tears by a **couple** of **scenes** **,** you 've got ice water in your **veins** .\n",
      "\n",
      "Epoch 28 Iter 2400 loss=95190.9391 elbo -84945.9688 ll -150.0710 kl 86497.1875 sf 1701.2753 selected 0.2972\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 28 iter 2465: dev loss 81885.3954 elbo -81885.3954 ll -146.7495 kl 83467.3452 sf 1728.6976 selected 0.2987 acc 0.3306\n",
      " dev0 [gold=3,pred=4]: it **'s** a lovely film **with** lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which **is** **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to tears by a couple **of** scenes **,** you **'ve** **got** ice water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 29 Iter 2500 loss=84983.8467 elbo -70473.1484 ll -154.6338 kl 72132.3203 sf 1813.8209 selected 0.2961\n",
      "\n",
      "# epoch 29 iter 2550: dev loss 74441.8314 elbo -74441.8314 ll -147.2113 kl 76044.6946 sf 1750.0738 selected 0.3091 acc 0.3515\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with **lovely** **performances** **by** **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which **is** probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: and if **you** **'re** not **nearly** **moved** to **tears** **by** a **couple** of **scenes** , **you** 've **got** **ice** water **in** **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 30 Iter 2600 loss=77154.1534 elbo -97334.4141 ll -150.0335 kl 99080.1719 sf 1895.7985 selected 0.2841\n",
      "\n",
      "# epoch 30 iter 2635: dev loss 67404.9882 elbo -67404.9882 ll -146.2700 kl 68983.6449 sf 1724.9242 selected 0.3011 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: it 's **a** **lovely** **film** **with** lovely **performances** **by** **buy** and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here **,** which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're **not** nearly moved to tears by **a** couple of scenes , you **'ve** **got** ice water **in** your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 31 Iter 2700 loss=68253.6961 elbo -75030.0078 ll -148.1716 kl 76521.4922 sf 1639.6569 selected 0.2877\n",
      "\n",
      "# epoch 31 iter 2720: dev loss 60669.3327 elbo -60669.3327 ll -147.8023 kl 62282.8214 sf 1761.2911 selected 0.3011 acc 0.3460\n",
      " dev0 [gold=3,pred=4]: it 's **a** **lovely** film with lovely **performances** **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** which is probably **for** the **best** .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're **not** nearly moved to **tears** **by** **a** **couple** of scenes , you **'ve** got ice water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 32 Iter 2800 loss=60294.1913 elbo -50800.2148 ll -156.5717 kl 52266.1133 sf 1622.4728 selected 0.3151\n",
      "\n",
      "# epoch 32 iter 2805: dev loss 54334.0726 elbo -54334.0726 ll -148.1956 kl 55945.2735 sf 1759.3958 selected 0.3018 acc 0.3551\n",
      " dev0 [gold=3,pred=4]: **it** 's a lovely film with lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=4]: and **if** you **'re** not **nearly** moved **to** tears **by** a couple of scenes **,** **you** 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 33 iter 2890: dev loss 48353.2258 elbo -48353.2258 ll -147.4681 kl 49963.8251 sf 1758.0685 selected 0.3007 acc 0.3406\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with lovely performances by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which **is** probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're not nearly **moved** to tears by a couple of scenes **,** you 've got **ice** **water** **in** your veins **.**\n",
      "\n",
      "Epoch 34 Iter 2900 loss=53411.9380 elbo -56488.3711 ll -151.4102 kl 58205.0352 sf 1868.0759 selected 0.3221\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 34 iter 2975: dev loss 42757.4049 elbo -42757.4049 ll -146.8393 kl 44337.1193 sf 1726.5542 selected 0.2997 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , **which** is **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're **not** nearly **moved** **to** tears by a couple of **scenes** , **you** 've got ice water **in** your veins .\n",
      "\n",
      "Epoch 35 Iter 3000 loss=45220.4237 elbo -43009.1680 ll -150.6309 kl 44569.5938 sf 1711.0594 selected 0.2982\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 35 iter 3060: dev loss 37489.6099 elbo -37489.6099 ll -146.0973 kl 39059.8574 sf 1716.3435 selected 0.3015 acc 0.3361\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** **,** which is probably for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not nearly moved to tears by **a** couple of scenes , **you** 've got ice **water** **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 36 Iter 3100 loss=38580.1244 elbo -45419.5547 ll -147.0252 kl 46859.8516 sf 1587.3282 selected 0.2971\n",
      "\n",
      "# epoch 36 iter 3145: dev loss 32543.1763 elbo -32543.1763 ll -146.5183 kl 34132.1656 sf 1735.5067 selected 0.3023 acc 0.3270\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film **with** lovely performances by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted **here** **,** which is **probably** for **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly moved **to** tears **by** a couple of scenes , you **'ve** got **ice** water **in** your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 37 Iter 3200 loss=33209.8381 elbo -29941.2324 ll -150.7113 kl 31567.6289 sf 1777.1063 selected 0.3214\n",
      "\n",
      "# epoch 37 iter 3230: dev loss 27960.1984 elbo -27960.1984 ll -148.0953 kl 29552.5794 sf 1740.4765 selected 0.2988 acc 0.3460\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** **with** lovely performances by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** unindicted here **,** which is **probably** for the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not **nearly** moved to **tears** by a **couple** of scenes , you **'ve** **got** **ice** water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 38 Iter 3300 loss=27779.1840 elbo -26545.5684 ll -142.7634 kl 27984.1875 sf 1581.3842 selected 0.2937\n",
      "\n",
      "# epoch 38 iter 3315: dev loss 23738.7637 elbo -23738.7637 ll -146.2789 kl 25314.4008 sf 1721.9167 selected 0.2980 acc 0.3506\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely **film** with lovely performances by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** **,** **which** **is** **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly moved to **tears** by **a** couple of scenes , you 've got ice water in **your** veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 39 Iter 3400 loss=22954.4038 elbo -19331.1953 ll -158.2565 kl 21183.0938 sf 2010.1576 selected 0.2920\n",
      "\n",
      "# epoch 39 iter 3400: dev loss 19829.6243 elbo -19829.6243 ll -147.3483 kl 21419.1351 sf 1736.8576 selected 0.3048 acc 0.3406\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely **film** with lovely **performances** **by** **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly moved **to** tears by **a** couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "\n",
      "# epoch 40 iter 3485: dev loss 16260.3727 elbo -16260.3727 ll -147.6567 kl 17859.8080 sf 1747.0926 selected 0.2996 acc 0.3397\n",
      " dev0 [gold=3,pred=3]: it 's **a** **lovely** film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which is **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** to tears by a couple **of** scenes , you **'ve** got ice water **in** your veins .\n",
      "\n",
      "Epoch 41 Iter 3500 loss=18124.3171 elbo -16825.9316 ll -145.4047 kl 18452.1367 sf 1771.6099 selected 0.2880\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 41 iter 3570: dev loss 13046.4853 elbo -13046.4853 ll -146.5074 kl 14635.5243 sf 1735.5463 selected 0.2984 acc 0.3379\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film **with** lovely **performances** by buy and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , **which** **is** **probably** for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not **nearly** moved to **tears** by a couple of scenes **,** you 've **got** ice water in your veins .\n",
      "\n",
      "Epoch 42 Iter 3600 loss=14260.6652 elbo -11706.6006 ll -149.0731 kl 13297.9404 sf 1740.4142 selected 0.2931\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 42 iter 3655: dev loss 10125.8983 elbo -10125.8983 ll -147.7829 kl 11739.6620 sf 1761.5470 selected 0.3008 acc 0.3406\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** lovely film **with** lovely performances **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which is probably for **the** best **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** **to** tears by a couple **of** scenes , you 've **got** ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 43 Iter 3700 loss=10647.8890 elbo -8453.9521 ll -152.6628 kl 10086.7344 sf 1785.4449 selected 0.2876\n",
      "\n",
      "# epoch 43 iter 3740: dev loss 7600.4137 elbo -7600.4137 ll -146.4041 kl 9174.8826 sf 1720.8726 selected 0.2946 acc 0.3524\n",
      " dev0 [gold=3,pred=4]: it 's a lovely film **with** **lovely** **performances** by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes **unindicted** here , which is probably **for** **the** **best** .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly **moved** to tears **by** a couple **of** **scenes** , you 've got ice water **in** your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 44 Iter 3800 loss=7667.5340 elbo -7814.1631 ll -150.4661 kl 9519.7588 sf 1856.0615 selected 0.3154\n",
      "\n",
      "# epoch 44 iter 3825: dev loss 5389.1605 elbo -5389.1605 ll -144.4116 kl 6932.1906 sf 1687.4415 selected 0.2944 acc 0.3560\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** **with** **lovely** performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** unindicted here , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not **nearly** moved **to** tears by a **couple** of scenes , you 've got **ice** water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 45 Iter 3900 loss=4968.7403 elbo -3722.7290 ll -150.1226 kl 5282.2402 sf 1709.6340 selected 0.2984\n",
      "\n",
      "# epoch 45 iter 3910: dev loss 3408.0195 elbo -3408.0195 ll -148.3718 kl 5011.3135 sf 1751.6659 selected 0.3018 acc 0.3215\n",
      " dev0 [gold=3,pred=4]: **it** **'s** **a** **lovely** film with lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** to tears by a **couple** of scenes , you **'ve** got **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 46 iter 3995: dev loss 1808.5917 elbo -1808.5917 ll -147.1148 kl 3406.1389 sf 1744.6621 selected 0.2991 acc 0.3533\n",
      " dev0 [gold=3,pred=4]: it 's a **lovely** **film** with lovely performances by buy and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here **,** which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not **nearly** **moved** to tears **by** a couple of scenes **,** **you** 've **got** **ice** water in your veins **.**\n",
      "\n",
      "Epoch 47 Iter 4000 loss=2780.7133 elbo -2207.7080 ll -144.5860 kl 3815.3804 sf 1752.2578 selected 0.3106\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 47 iter 4080: dev loss 512.2727 elbo -512.2727 ll -146.8753 kl 2115.6878 sf 1750.2904 selected 0.3051 acc 0.3351\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with lovely performances by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=1]: **no** one **goes** unindicted here , **which** is **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you **'re** not nearly moved to tears by a couple of **scenes** **,** you **'ve** got ice **water** in your veins .\n",
      "\n",
      "Epoch 48 Iter 4100 loss=1030.3012 elbo 14.1636 ll -148.1947 kl 1604.3904 sf 1766.7489 selected 0.3003\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 48 iter 4165: dev loss -456.2868 elbo 456.2868 ll -147.3560 kl 1134.2108 sf 1737.8536 selected 0.2968 acc 0.3342\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted **here** , which **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're not nearly moved **to** tears **by** a **couple** of **scenes** , you 've **got** **ice** water in **your** **veins** .\n",
      "\n",
      "Epoch 49 Iter 4200 loss=-187.9479 elbo 469.4690 ll -142.1099 kl 1011.2496 sf 1622.8285 selected 0.3006\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 49 iter 4250: dev loss -1116.8268 elbo 1116.8268 ll -146.4964 kl 458.4681 sf 1721.7913 selected 0.2981 acc 0.3515\n",
      " dev0 [gold=3,pred=1]: it **'s** a **lovely** film **with** **lovely** performances **by** buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here **,** which is **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** 're not nearly moved to tears **by** a couple of scenes , **you** 've got ice **water** in **your** **veins** .\n",
      "\n",
      "Epoch 50 Iter 4300 loss=-1081.1368 elbo 651.8628 ll -65.2458 kl 30.9798 sf 748.0884 selected 0.2942\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 50 iter 4335: dev loss -1494.5043 elbo 1494.5043 ll -146.4557 kl 84.8432 sf 1725.8033 selected 0.2969 acc 0.3460\n",
      " dev0 [gold=3,pred=1]: **it** 's a lovely film with lovely performances **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here **,** which **is** probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved to **tears** **by** a **couple** of scenes , you **'ve** got ice **water** in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 51 Iter 4400 loss=-1506.2708 elbo 1420.3879 ll -148.5848 kl 3.1159 sf 1572.0886 selected 0.2939\n",
      "\n",
      "# epoch 51 iter 4420: dev loss -1618.4247 elbo 1618.4247 ll -148.8694 kl 2.2155 sf 1769.5097 selected 0.3036 acc 0.3215\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** lovely film **with** lovely performances **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here , **which** **is** **probably** for **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** **nearly** moved **to** tears by a couple of **scenes** , **you** 've **got** ice **water** in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 52 Iter 4500 loss=-1588.5983 elbo 1554.0116 ll -148.4390 kl 0.4285 sf 1702.8792 selected 0.3157\n",
      "\n",
      "# epoch 52 iter 4505: dev loss -1613.0484 elbo 1613.0484 ll -147.9846 kl 0.6053 sf 1761.6383 selected 0.3047 acc 0.3451\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which is **probably** for **the** best .\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're **not** nearly moved to tears **by** **a** **couple** **of** scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 53 iter 4590: dev loss -1579.7179 elbo 1579.7179 ll -146.6405 kl 0.9266 sf 1727.2849 selected 0.2996 acc 0.3433\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film **with** lovely **performances** **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , which is probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to tears by **a** couple **of** **scenes** , you 've got **ice** **water** in **your** **veins** .\n",
      "\n",
      "Epoch 54 Iter 4600 loss=-1581.6601 elbo 1670.1716 ll -146.6330 kl 0.3597 sf 1817.1642 selected 0.3006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "\n",
      "# epoch 54 iter 4675: dev loss -1598.2814 elbo 1598.2814 ll -148.2918 kl 0.5385 sf 1747.1117 selected 0.3008 acc 0.3279\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** film with lovely performances **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which **is** probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved **to** **tears** **by** **a** couple of scenes , you 've **got** ice water in your **veins** .\n",
      "\n",
      "Epoch 55 Iter 4700 loss=-1573.3181 elbo 1437.0529 ll -138.2841 kl 0.3499 sf 1575.6870 selected 0.2922\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 55 iter 4760: dev loss -1582.8901 elbo 1582.8901 ll -146.3341 kl 0.1692 sf 1729.3934 selected 0.3046 acc 0.3606\n",
      " dev0 [gold=3,pred=3]: it 's **a** **lovely** film with lovely performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , **which** is **probably** for **the** **best** .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** **nearly** **moved** **to** tears by **a** **couple** of scenes , you 've got ice water in **your** veins .\n",
      "\n",
      "Epoch 56 Iter 4800 loss=-1567.3448 elbo 1704.0383 ll -152.7504 kl 0.2743 sf 1857.0632 selected 0.3260\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 56 iter 4845: dev loss -1597.2580 elbo 1597.2580 ll -146.3521 kl 0.3865 sf 1743.9966 selected 0.3044 acc 0.3651\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with lovely performances by **buy** and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , which is probably for **the** best .\n",
      " dev2 [gold=3,pred=4]: and **if** you **'re** not **nearly** **moved** to tears by a **couple** of scenes , you **'ve** got ice water **in** your **veins** .\n",
      "\n",
      "Epoch 57 Iter 4900 loss=-1572.4382 elbo 1567.0096 ll -156.4974 kl 0.3880 sf 1723.8950 selected 0.2814\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 57 iter 4930: dev loss -1568.2285 elbo 1568.2285 ll -145.2455 kl 0.1384 sf 1713.6124 selected 0.3011 acc 0.3451\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** **lovely** **film** **with** **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly moved to tears by a couple of **scenes** , **you** 've **got** **ice** water in **your** veins .\n",
      "\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Shuffling training data\n",
      "Epoch 58 Iter 5000 loss=-1572.5357 elbo 1401.7915 ll -139.9695 kl 0.4092 sf 1542.1703 selected 0.2843\n",
      "\n",
      "# epoch 58 iter 5015: dev loss -1600.8622 elbo 1600.8622 ll -147.4446 kl 0.3643 sf 1748.6710 selected 0.3000 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: it **'s** a **lovely** film with **lovely** performances **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which is **probably** for the **best** .\n",
      " dev2 [gold=3,pred=3]: and **if** **you** **'re** not **nearly** moved to **tears** by a couple of scenes , you 've got ice **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 59 Iter 5100 loss=-1575.7412 elbo 1239.5088 ll -136.4458 kl 0.1583 sf 1376.1128 selected 0.2954\n",
      "\n",
      "# epoch 59 iter 5100: dev loss -1606.7128 elbo 1606.7128 ll -146.8860 kl 0.1631 sf 1753.7619 selected 0.3034 acc 0.3451\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by **buy** and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here **,** which **is** **probably** for **the** best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're **not** **nearly** moved **to** tears **by** a **couple** of scenes , you **'ve** **got** **ice** water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 60 iter 5185: dev loss -1575.8402 elbo 1575.8402 ll -145.8867 kl 0.1270 sf 1721.8538 selected 0.3001 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with lovely **performances** by buy **and** **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** unindicted here , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you **'re** not **nearly** **moved** **to** tears by a couple of **scenes** , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 61 Iter 5200 loss=-1558.0164 elbo 1534.9786 ll -148.3178 kl 0.1280 sf 1683.4244 selected 0.2937\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 61 iter 5270: dev loss -1566.9974 elbo 1566.9974 ll -145.0123 kl 0.4455 sf 1712.4552 selected 0.3030 acc 0.3433\n",
      " dev0 [gold=3,pred=4]: it **'s** **a** lovely film with lovely **performances** by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which **is** probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** 're not nearly moved **to** tears **by** a **couple** of scenes , you 've **got** ice **water** in your veins .\n",
      "\n",
      "Epoch 62 Iter 5300 loss=-1569.7367 elbo 1530.3062 ll -150.3714 kl 0.1835 sf 1680.8610 selected 0.2952\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 62 iter 5355: dev loss -1556.3614 elbo 1556.3614 ll -144.8064 kl 0.3180 sf 1701.4858 selected 0.2973 acc 0.3651\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with **lovely** **performances** **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no **one** goes **unindicted** here , which is probably **for** the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly **moved** **to** **tears** by **a** couple of scenes , **you** 've got ice water in **your** veins .\n",
      "\n",
      "Epoch 63 Iter 5400 loss=-1560.1958 elbo 1511.0153 ll -148.3223 kl 0.0687 sf 1659.4065 selected 0.2847\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 63 iter 5440: dev loss -1571.3305 elbo 1571.3305 ll -146.1147 kl 0.1978 sf 1717.6429 selected 0.2951 acc 0.3515\n",
      " dev0 [gold=3,pred=4]: it 's **a** lovely **film** with **lovely** **performances** by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** , which is **probably** **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved **to** tears by a couple of scenes , you 've got ice water in **your** veins **.**\n",
      "\n",
      "Epoch 64 Iter 5500 loss=-1566.9944 elbo 1659.0447 ll -150.1539 kl 0.0030 sf 1809.2015 selected 0.3129\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 64 iter 5525: dev loss -1603.1173 elbo 1603.1173 ll -147.2465 kl 0.2719 sf 1750.6358 selected 0.3014 acc 0.3433\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with **lovely** performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** **you** **'re** not nearly **moved** **to** tears by a couple of scenes , you 've **got** ice water **in** **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 65 Iter 5600 loss=-1559.9823 elbo 1486.4153 ll -142.6958 kl 0.1218 sf 1629.2329 selected 0.3005\n",
      "\n",
      "# epoch 65 iter 5610: dev loss -1591.6653 elbo 1591.6653 ll -146.9781 kl 0.2613 sf 1738.9048 selected 0.3015 acc 0.3460\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** **lovely** film **with** lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** **here** , which **is** probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** **'re** not nearly moved **to** **tears** **by** a **couple** of scenes **,** you 've **got** ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 66 iter 5695: dev loss -1585.5772 elbo 1585.5772 ll -147.5915 kl 0.1780 sf 1733.3467 selected 0.2949 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no **one** goes unindicted here , which is probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not **nearly** moved to tears **by** a couple of scenes **,** you 've **got** ice water in your **veins** .\n",
      "\n",
      "Epoch 67 Iter 5700 loss=-1556.1753 elbo 1849.9827 ll -150.3514 kl 0.3845 sf 2000.7188 selected 0.3089\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 67 iter 5780: dev loss -1593.1053 elbo 1593.1053 ll -146.1824 kl 0.3466 sf 1739.6343 selected 0.3082 acc 0.3479\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film **with** lovely **performances** **by** buy and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** **,** which is **probably** for **the** best **.**\n",
      " dev2 [gold=3,pred=3]: **and** **if** you **'re** **not** nearly **moved** to tears by a **couple** of scenes , you 've got **ice** water in your **veins** .\n",
      "\n",
      "Epoch 68 Iter 5800 loss=-1563.1248 elbo 1489.3788 ll -151.0879 kl 0.4280 sf 1640.8948 selected 0.2826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "\n",
      "# epoch 68 iter 5865: dev loss -1581.2089 elbo 1581.2089 ll -145.2586 kl 0.1617 sf 1726.6291 selected 0.3059 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with **lovely** **performances** by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** **unindicted** here , which is probably for **the** best .\n",
      " dev2 [gold=3,pred=1]: and if you **'re** not nearly moved **to** tears by **a** **couple** of scenes , **you** 've **got** ice water in your **veins** .\n",
      "\n",
      "Epoch    68: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 69 Iter 5900 loss=-1570.0932 elbo 1649.0151 ll -148.7312 kl 0.2352 sf 1797.9813 selected 0.3007\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 69 iter 5950: dev loss -1575.6166 elbo 1575.6166 ll -145.8104 kl 0.0731 sf 1721.5001 selected 0.3027 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely **film** with lovely performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted **here** , which is probably for **the** best **.**\n",
      " dev2 [gold=3,pred=3]: **and** if you **'re** not nearly moved **to** **tears** by **a** couple of scenes **,** you **'ve** **got** **ice** water **in** your veins **.**\n",
      "\n",
      "Epoch 70 Iter 6000 loss=-1554.3464 elbo 1442.9551 ll -139.6417 kl 0.1320 sf 1582.7290 selected 0.2975\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 70 iter 6035: dev loss -1569.3374 elbo 1569.3374 ll -146.1709 kl 0.0168 sf 1715.5250 selected 0.2950 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** **lovely** film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not **nearly** **moved** **to** tears **by** a couple of **scenes** , you 've **got** **ice** water **in** **your** **veins** .\n",
      "\n",
      "Epoch 71 Iter 6100 loss=-1566.7513 elbo 1481.1085 ll -145.8282 kl 0.1861 sf 1627.1226 selected 0.3071\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 71 iter 6120: dev loss -1586.9211 elbo 1586.9211 ll -146.3473 kl 0.1384 sf 1733.4069 selected 0.2988 acc 0.3406\n",
      " dev0 [gold=3,pred=4]: **it** 's a **lovely** film with lovely performances by **buy** **and** **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , **which** **is** probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you **'re** **not** nearly **moved** **to** **tears** by a couple **of** **scenes** , you 've **got** ice **water** **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 72 Iter 6200 loss=-1548.8719 elbo 1494.6973 ll -141.2715 kl 0.2905 sf 1636.2593 selected 0.2858\n",
      "\n",
      "# epoch 72 iter 6205: dev loss -1553.9269 elbo 1553.9269 ll -144.9452 kl 0.1457 sf 1699.0178 selected 0.2961 acc 0.3524\n",
      " dev0 [gold=3,pred=3]: it **'s** a **lovely** **film** with **lovely** **performances** by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , which is probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're **not** nearly moved **to** tears by a couple of scenes , you 've got **ice** water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 73 iter 6290: dev loss -1578.3895 elbo 1578.3895 ll -146.3622 kl 0.2372 sf 1724.9889 selected 0.2992 acc 0.3542\n",
      " dev0 [gold=3,pred=4]: **it** 's a lovely film with **lovely** performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** **unindicted** here , **which** **is** probably for the best .\n",
      " dev2 [gold=3,pred=1]: **and** if you **'re** **not** nearly moved to tears by a couple of scenes , you **'ve** got ice water **in** your veins .\n",
      "\n",
      "Epoch 74 Iter 6300 loss=-1567.6226 elbo 1494.2048 ll -141.6971 kl 0.0385 sf 1635.9406 selected 0.2959\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 74 iter 6375: dev loss -1564.4086 elbo 1564.4086 ll -145.1133 kl 0.4121 sf 1709.9341 selected 0.3005 acc 0.3615\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** **here** **,** **which** **is** probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** **'re** **not** nearly **moved** to **tears** by a couple of **scenes** , you 've got ice water in your **veins** .\n",
      "\n",
      "Epoch 75 Iter 6400 loss=-1559.9398 elbo 1561.2784 ll -145.2038 kl 0.2898 sf 1706.7725 selected 0.2908\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 75 iter 6460: dev loss -1582.5366 elbo 1582.5366 ll -145.9975 kl -0.0414 sf 1728.4927 selected 0.3035 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** film **with** **lovely** **performances** **by** **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** unindicted **here** , **which** **is** probably **for** **the** best .\n",
      " dev2 [gold=3,pred=4]: and if you 're not nearly moved to tears by a couple of scenes **,** you 've got **ice** water in your **veins** .\n",
      "\n",
      "Epoch 76 Iter 6500 loss=-1574.0180 elbo 1649.5929 ll -153.4546 kl 0.3786 sf 1803.4261 selected 0.3036\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 76 iter 6545: dev loss -1599.9220 elbo 1599.9220 ll -148.0538 kl 0.3049 sf 1748.2807 selected 0.2979 acc 0.3579\n",
      " dev0 [gold=3,pred=1]: it **'s** **a** lovely film with lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** **unindicted** here **,** which is probably for the best **.**\n",
      " dev2 [gold=3,pred=1]: and if **you** 're not nearly moved to tears by a couple of scenes **,** you 've got ice **water** **in** **your** veins .\n",
      "\n",
      "Epoch 77 Iter 6600 loss=-1575.4497 elbo 1635.9082 ll -149.7368 kl 0.1247 sf 1785.7701 selected 0.2974\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 77 iter 6630: dev loss -1580.3149 elbo 1580.3149 ll -146.1008 kl 0.1589 sf 1726.5746 selected 0.2962 acc 0.3479\n",
      " dev0 [gold=3,pred=3]: **it** **'s** **a** **lovely** film with **lovely** performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're **not** nearly **moved** **to** **tears** by a couple of scenes **,** you 've got **ice** water in **your** veins .\n",
      "\n",
      "Epoch 78 Iter 6700 loss=-1552.3984 elbo 1494.2047 ll -141.8580 kl 0.2272 sf 1636.2899 selected 0.2839\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 78 iter 6715: dev loss -1593.9070 elbo 1593.9070 ll -146.5596 kl 0.3998 sf 1740.8663 selected 0.2986 acc 0.3506\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** film **with** lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , **which** is probably **for** the **best** .\n",
      " dev2 [gold=3,pred=3]: and if **you** **'re** not nearly **moved** **to** tears by a **couple** of scenes , you **'ve** got ice water in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 79 Iter 6800 loss=-1547.6490 elbo 1589.2664 ll -145.0190 kl 0.1694 sf 1734.4546 selected 0.3271\n",
      "\n",
      "# epoch 79 iter 6800: dev loss -1587.0675 elbo 1587.0675 ll -146.8795 kl 0.4218 sf 1734.3689 selected 0.3005 acc 0.3388\n",
      " dev0 [gold=3,pred=1]: **it** 's a lovely **film** **with** lovely performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** **here** , which is probably **for** **the** best **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly moved to tears **by** **a** **couple** **of** scenes , **you** 've got **ice** **water** in **your** veins .\n",
      "\n",
      "Epoch    79: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 80 iter 6885: dev loss -1602.1198 elbo 1602.1198 ll -146.6504 kl 0.2784 sf 1749.0485 selected 0.3092 acc 0.3433\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** lovely film with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted **here** , which **is** probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** 're not nearly moved to tears by a couple of scenes , **you** 've got ice **water** in your veins .\n",
      "\n",
      "Epoch 81 Iter 6900 loss=-1565.1390 elbo 1628.1407 ll -143.1541 kl 0.0780 sf 1771.3729 selected 0.3071\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 81 iter 6970: dev loss -1584.6577 elbo 1584.6577 ll -146.1356 kl 0.1590 sf 1730.9523 selected 0.3023 acc 0.3506\n",
      " dev0 [gold=3,pred=4]: it 's **a** **lovely** film with lovely **performances** by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=4]: no one **goes** unindicted here , which **is** probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by **a** couple of scenes **,** you **'ve** **got** ice **water** **in** your **veins** .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Iter 7000 loss=-1556.3792 elbo 1654.3831 ll -152.6875 kl 0.4039 sf 1807.4745 selected 0.2977\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 82 iter 7055: dev loss -1580.9760 elbo 1580.9760 ll -146.4569 kl 0.2072 sf 1727.6401 selected 0.2984 acc 0.3415\n",
      " dev0 [gold=3,pred=4]: **it** 's a lovely film with lovely **performances** **by** buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** **which** is **probably** **for** the best **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly moved **to** **tears** by **a** couple of scenes , you **'ve** got ice **water** **in** your veins .\n",
      "\n",
      "Epoch 83 Iter 7100 loss=-1559.4362 elbo 1540.3859 ll -151.6337 kl -0.0885 sf 1691.9314 selected 0.2871\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 83 iter 7140: dev loss -1562.7775 elbo 1562.7775 ll -144.9927 kl 0.1672 sf 1707.9374 selected 0.2987 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film **with** **lovely** **performances** by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** which is **probably** for the best **.**\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're **not** **nearly** moved to tears by **a** couple of scenes , **you** 've **got** ice water in your veins .\n",
      "\n",
      "Epoch 84 Iter 7200 loss=-1571.6336 elbo 1522.1178 ll -142.0296 kl 0.1481 sf 1664.2954 selected 0.3028\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 84 iter 7225: dev loss -1593.8360 elbo 1593.8360 ll -146.3881 kl 0.1123 sf 1740.3364 selected 0.2999 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film **with** lovely performances by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no **one** goes unindicted here , which is probably **for** the **best** **.**\n",
      " dev2 [gold=3,pred=3]: **and** **if** **you** 're not **nearly** moved to tears by a couple of **scenes** **,** you 've got ice water in **your** **veins** .\n",
      "\n",
      "Epoch 85 Iter 7300 loss=-1563.6587 elbo 1492.0670 ll -145.4328 kl 0.1251 sf 1637.6249 selected 0.2820\n",
      "\n",
      "# epoch 85 iter 7310: dev loss -1592.8834 elbo 1592.8834 ll -147.4575 kl 0.0168 sf 1740.3578 selected 0.2979 acc 0.3460\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film **with** lovely performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** **which** is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** **'re** not **nearly** moved to **tears** by a couple **of** **scenes** , **you** 've got ice water **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 86 iter 7395: dev loss -1570.6597 elbo 1570.6597 ll -146.1892 kl 0.0869 sf 1716.9358 selected 0.2965 acc 0.3497\n",
      " dev0 [gold=3,pred=4]: **it** **'s** **a** lovely **film** with lovely performances by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , **which** is probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you **'re** not nearly moved to **tears** by a **couple** **of** **scenes** , you 've **got** ice water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 87 Iter 7400 loss=-1556.0932 elbo 1526.4968 ll -144.7926 kl 0.2589 sf 1671.5483 selected 0.3002\n",
      "\n",
      "# epoch 87 iter 7480: dev loss -1581.5659 elbo 1581.5659 ll -146.3669 kl 0.2039 sf 1728.1367 selected 0.2999 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by **buy** **and** **accorsi** **.**\n",
      " dev1 [gold=2,pred=1]: no **one** goes unindicted **here** **,** **which** is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly moved to tears by a couple of scenes , **you** **'ve** **got** ice water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 88 Iter 7500 loss=-1552.0246 elbo 1533.2928 ll -151.8307 kl 0.1252 sf 1685.2485 selected 0.3086\n",
      "\n",
      "# epoch 88 iter 7565: dev loss -1574.1348 elbo 1574.1348 ll -146.1552 kl 0.2787 sf 1720.5687 selected 0.3007 acc 0.3451\n",
      " dev0 [gold=3,pred=3]: it **'s** a **lovely** film **with** **lovely** **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** 're **not** **nearly** **moved** to tears by a couple of scenes , **you** 've got ice water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 89 Iter 7600 loss=-1576.2899 elbo 1529.0975 ll -147.5608 kl 0.4244 sf 1677.0826 selected 0.3056\n",
      "\n",
      "# epoch 89 iter 7650: dev loss -1596.1317 elbo 1596.1317 ll -146.7243 kl 0.1509 sf 1743.0071 selected 0.3031 acc 0.3415\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film with lovely performances by buy and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** unindicted **here** , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if **you** 're not **nearly** **moved** to tears by a **couple** **of** **scenes** **,** you 've **got** ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 90 Iter 7700 loss=-1545.4068 elbo 1560.0060 ll -142.5765 kl 0.0700 sf 1702.6525 selected 0.3045\n",
      "\n",
      "# epoch 90 iter 7735: dev loss -1556.9478 elbo 1556.9478 ll -144.5714 kl 0.2117 sf 1701.7309 selected 0.3008 acc 0.3597\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely **film** **with** lovely **performances** by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which is probably for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** to tears by **a** **couple** of scenes **,** you 've got ice water **in** your **veins** .\n",
      "\n",
      "Epoch    90: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Shuffling training data\n",
      "Epoch 91 Iter 7800 loss=-1573.4697 elbo 1588.6218 ll -141.5204 kl 0.2750 sf 1730.4171 selected 0.3019\n",
      "\n",
      "# epoch 91 iter 7820: dev loss -1558.0231 elbo 1558.0231 ll -144.7976 kl 0.1842 sf 1703.0049 selected 0.3017 acc 0.3515\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** lovely film **with** lovely performances by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted **here** , which **is** probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved to tears by a couple of scenes , you **'ve** got **ice** water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 92 Iter 7900 loss=-1554.3187 elbo 1662.6212 ll -148.9452 kl -0.0080 sf 1811.5585 selected 0.3170\n",
      "\n",
      "# epoch 92 iter 7905: dev loss -1586.2111 elbo 1586.2111 ll -146.6206 kl 0.1313 sf 1732.9629 selected 0.2969 acc 0.3488\n",
      " dev0 [gold=3,pred=4]: it 's a **lovely** film **with** lovely **performances** by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** **here** **,** which is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: and **if** you **'re** not nearly **moved** to tears by a couple of scenes , **you** 've got ice water in your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 93 iter 7990: dev loss -1556.0234 elbo 1556.0234 ll -145.0733 kl 0.1095 sf 1701.2062 selected 0.2967 acc 0.3479\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no **one** goes unindicted here **,** **which** is probably **for** the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly **moved** **to** tears by **a** couple of **scenes** , **you** **'ve** got **ice** water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 94 Iter 8000 loss=-1544.3191 elbo 1539.7224 ll -142.1611 kl 0.1788 sf 1682.0625 selected 0.3197\n",
      "\n",
      "# epoch 94 iter 8075: dev loss -1569.3542 elbo 1569.3542 ll -145.2760 kl 0.2347 sf 1714.8649 selected 0.3023 acc 0.3551\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** which is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved to tears by **a** couple of **scenes** , **you** 've got ice water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 95 Iter 8100 loss=-1562.3553 elbo 1540.5498 ll -142.5291 kl 0.2685 sf 1683.3477 selected 0.2934\n",
      "\n",
      "# epoch 95 iter 8160: dev loss -1583.4250 elbo 1583.4250 ll -147.5494 kl 0.0536 sf 1731.0280 selected 0.2917 acc 0.3279\n",
      " dev0 [gold=3,pred=3]: it **'s** a **lovely** film **with** **lovely** performances **by** buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not **nearly** **moved** **to** **tears** by a couple **of** scenes **,** you 've got ice water in **your** veins **.**\n",
      "\n",
      "Shuffling training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Iter 8200 loss=-1565.9061 elbo 1556.3948 ll -144.0162 kl 0.1683 sf 1700.5793 selected 0.3172\n",
      "\n",
      "# epoch 96 iter 8245: dev loss -1585.7851 elbo 1585.7851 ll -146.2385 kl 0.1473 sf 1732.1710 selected 0.3001 acc 0.3342\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film with **lovely** performances **by** **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here **,** which is probably for **the** best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly **moved** to tears by **a** couple of **scenes** **,** you 've **got** **ice** water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 97 Iter 8300 loss=-1543.6847 elbo 1552.4044 ll -154.6031 kl 0.2124 sf 1707.2200 selected 0.2918\n",
      "\n",
      "# epoch 97 iter 8330: dev loss -1592.7169 elbo 1592.7169 ll -146.9596 kl 0.2171 sf 1739.8935 selected 0.2993 acc 0.3506\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** with **lovely** **performances** **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly **moved** to tears by a **couple** **of** scenes **,** **you** 've **got** ice water in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 98 Iter 8400 loss=-1561.1122 elbo 1391.9493 ll -144.7446 kl 0.2495 sf 1536.9432 selected 0.2794\n",
      "\n",
      "# epoch 98 iter 8415: dev loss -1560.5501 elbo 1560.5501 ll -146.1265 kl 0.0947 sf 1706.7712 selected 0.2938 acc 0.3488\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with **lovely** performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here **,** which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're not nearly moved to **tears** by **a** couple of **scenes** , **you** 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 99 Iter 8500 loss=-1551.4798 elbo 1557.0864 ll -150.0548 kl 0.1292 sf 1707.2708 selected 0.3014\n",
      "\n",
      "# epoch 99 iter 8500: dev loss -1569.4695 elbo 1569.4695 ll -146.4556 kl 0.1680 sf 1716.0931 selected 0.2928 acc 0.3479\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** **lovely** film **with** **lovely** **performances** **by** **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** **unindicted** **here** , which **is** probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved to tears **by** a **couple** of scenes , **you** 've got ice water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 100 iter 8585: dev loss -1580.6605 elbo 1580.6605 ll -146.9917 kl 0.1228 sf 1727.7751 selected 0.2993 acc 0.3533\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film **with** lovely **performances** by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no **one** **goes** **unindicted** here **,** which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you **'re** **not** **nearly** moved **to** tears by **a** **couple** of scenes , you 've got ice water **in** your **veins** .\n",
      "\n",
      "Epoch 101 Iter 8600 loss=-1561.3851 elbo 721.1796 ll -64.3692 kl 0.0255 sf 785.5742 selected 0.3231\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 101 iter 8670: dev loss -1564.7247 elbo 1564.7247 ll -146.2690 kl 0.2791 sf 1711.2728 selected 0.2961 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it **'s** a **lovely** film **with** lovely performances by buy and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , which **is** probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved to tears by a couple **of** scenes **,** **you** 've got ice water in **your** veins **.**\n",
      "\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Shuffling training data\n",
      "Epoch 102 Iter 8700 loss=-1552.1501 elbo 1557.6813 ll -145.4276 kl 0.1256 sf 1703.2345 selected 0.3056\n",
      "\n",
      "# epoch 102 iter 8755: dev loss -1568.7060 elbo 1568.7060 ll -145.9822 kl 0.3444 sf 1715.0326 selected 0.2996 acc 0.3424\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film **with** lovely performances by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , **which** **is** **probably** for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not nearly moved to tears by a couple **of** **scenes** , you 've **got** ice **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 103 Iter 8800 loss=-1557.3031 elbo 1503.2899 ll -144.7867 kl 0.3036 sf 1648.3802 selected 0.2931\n",
      "\n",
      "# epoch 103 iter 8840: dev loss -1557.9289 elbo 1557.9289 ll -145.4052 kl 0.0427 sf 1703.3769 selected 0.2944 acc 0.3606\n",
      " dev0 [gold=3,pred=3]: it 's **a** **lovely** **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** **unindicted** **here** , which is probably **for** **the** best **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** to **tears** by **a** couple **of** scenes , you 've got **ice** water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 104 Iter 8900 loss=-1558.3241 elbo 1362.8928 ll -147.1459 kl 0.1148 sf 1510.1536 selected 0.2841\n",
      "\n",
      "# epoch 104 iter 8925: dev loss -1571.6535 elbo 1571.6535 ll -146.3238 kl 0.2067 sf 1718.1841 selected 0.2970 acc 0.3479\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** **film** with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** unindicted here , **which** **is** probably for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly moved to **tears** by a couple of **scenes** , **you** 've **got** **ice** **water** in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 105 Iter 9000 loss=-1553.8460 elbo 1541.6699 ll -140.2253 kl 0.1515 sf 1682.0468 selected 0.3062\n",
      "\n",
      "# epoch 105 iter 9010: dev loss -1590.5465 elbo 1590.5465 ll -147.3643 kl -0.0042 sf 1737.9067 selected 0.2991 acc 0.3488\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film **with** lovely performances **by** **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** **,** which **is** probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to **tears** **by** a **couple** **of** **scenes** , you **'ve** got ice water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 106 iter 9095: dev loss -1585.1440 elbo 1585.1440 ll -146.2156 kl 0.1821 sf 1731.5417 selected 0.3011 acc 0.3424\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** **lovely** **film** **with** **lovely** **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , which **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** to tears **by** a **couple** of **scenes** **,** you 've **got** ice water in your veins .\n",
      "\n",
      "Epoch 107 Iter 9100 loss=-1552.5333 elbo 1487.2151 ll -145.6400 kl 0.3538 sf 1633.2091 selected 0.2932\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 107 iter 9180: dev loss -1569.9598 elbo 1569.9598 ll -145.1844 kl 0.0211 sf 1715.1654 selected 0.2973 acc 0.3624\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** **,** **which** is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly **moved** to tears by a couple **of** scenes **,** **you** 've **got** ice water in your veins **.**\n",
      "\n",
      "Epoch 108 Iter 9200 loss=-1563.3701 elbo 1761.6974 ll -157.3780 kl -0.0607 sf 1919.0148 selected 0.2945\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 108 iter 9265: dev loss -1541.0142 elbo 1541.0142 ll -145.1463 kl 0.2844 sf 1686.4449 selected 0.2914 acc 0.3569\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film **with** lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 109 Iter 9300 loss=-1540.6160 elbo 1485.6218 ll -144.7553 kl 0.0439 sf 1630.4210 selected 0.3038\n",
      "\n",
      "# epoch 109 iter 9350: dev loss -1581.4281 elbo 1581.4281 ll -146.0008 kl 0.3101 sf 1727.7390 selected 0.2995 acc 0.3433\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** lovely film **with** **lovely** performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , which **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly **moved** to tears **by** **a** couple **of** **scenes** , you 've **got** ice water in your **veins** .\n",
      "\n",
      "Shuffling training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 Iter 9400 loss=-1562.3662 elbo 1600.2639 ll -143.7426 kl 0.3537 sf 1744.3602 selected 0.3086\n",
      "\n",
      "# epoch 110 iter 9435: dev loss -1597.7809 elbo 1597.7809 ll -147.6116 kl 0.2882 sf 1745.6808 selected 0.3002 acc 0.3206\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** **film** **with** lovely **performances** **by** **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not nearly **moved** **to** tears by a couple of **scenes** , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 111 Iter 9500 loss=-1557.8449 elbo 1469.8243 ll -146.1301 kl 0.1243 sf 1616.0786 selected 0.3067\n",
      "\n",
      "# epoch 111 iter 9520: dev loss -1596.6645 elbo 1596.6645 ll -147.3060 kl 0.1079 sf 1744.0784 selected 0.3022 acc 0.3579\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely **performances** by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted **here** , **which** is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved to **tears** **by** **a** **couple** **of** **scenes** **,** **you** 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 112 Iter 9600 loss=-1566.2148 elbo 1568.2184 ll -149.2926 kl 0.1955 sf 1717.7067 selected 0.3110\n",
      "\n",
      "# epoch 112 iter 9605: dev loss -1598.1037 elbo 1598.1037 ll -146.9727 kl 0.1317 sf 1745.2080 selected 0.3009 acc 0.3479\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely **performances** **by** buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=1]: **no** **one** goes unindicted here **,** which is probably for **the** best .\n",
      " dev2 [gold=3,pred=1]: **and** **if** you 're not nearly moved to tears **by** a couple of scenes , you 've got ice **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 113 iter 9690: dev loss -1591.3660 elbo 1591.3660 ll -146.6033 kl 0.1212 sf 1738.0906 selected 0.3033 acc 0.3397\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes **unindicted** here **,** which is probably **for** the best .\n",
      " dev2 [gold=3,pred=4]: **and** **if** you **'re** **not** nearly moved **to** tears by **a** couple of scenes **,** you **'ve** got ice water in your veins .\n",
      "\n",
      "Epoch 114 Iter 9700 loss=-1546.6227 elbo 1577.5186 ll -149.7768 kl 0.0988 sf 1727.3942 selected 0.2923\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 114 iter 9775: dev loss -1595.6965 elbo 1595.6965 ll -146.1884 kl -0.0326 sf 1741.8523 selected 0.3030 acc 0.3488\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** **film** with lovely **performances** **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , **which** is probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved **to** **tears** by a **couple** of scenes , **you** 've got ice water **in** your veins .\n",
      "\n",
      "Epoch 115 Iter 9800 loss=-1571.5518 elbo 1347.3572 ll -139.6701 kl 0.1791 sf 1487.2064 selected 0.3007\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 115 iter 9860: dev loss -1590.3113 elbo 1590.3113 ll -146.7915 kl 0.1141 sf 1737.2168 selected 0.2991 acc 0.3388\n",
      " dev0 [gold=3,pred=4]: it 's **a** **lovely** film with **lovely** performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one **goes** **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're **not** nearly moved to tears by **a** couple of **scenes** **,** you 've **got** ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 116 Iter 9900 loss=-1552.2731 elbo 1705.2972 ll -150.1931 kl 0.0903 sf 1855.5807 selected 0.2998\n",
      "\n",
      "# epoch 116 iter 9945: dev loss -1574.8835 elbo 1574.8835 ll -144.9977 kl 0.0097 sf 1719.8909 selected 0.3024 acc 0.3588\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** film with lovely **performances** by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , which is **probably** for the best **.**\n",
      " dev2 [gold=3,pred=3]: **and** **if** you **'re** not nearly moved to tears by a **couple** of **scenes** **,** you **'ve** **got** ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 117 Iter 10000 loss=-1565.0180 elbo 1614.5542 ll -153.6245 kl -0.0024 sf 1768.1764 selected 0.2994\n",
      "\n",
      "# epoch 117 iter 10030: dev loss -1573.4978 elbo 1573.4978 ll -145.8012 kl 0.3549 sf 1719.6538 selected 0.2999 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with **lovely** performances by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , which is **probably** **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** **moved** **to** tears by a couple of scenes , you **'ve** **got** ice **water** **in** **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 118 Iter 10100 loss=-1576.1962 elbo 1533.0695 ll -146.1887 kl 0.1120 sf 1679.3700 selected 0.2881\n",
      "\n",
      "# epoch 118 iter 10115: dev loss -1585.0659 elbo 1585.0659 ll -146.5812 kl 0.2160 sf 1731.8631 selected 0.2997 acc 0.3388\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here **,** which **is** probably for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to tears **by** **a** couple of **scenes** , **you** 've got ice **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 119 Iter 10200 loss=-1560.6772 elbo 1678.0216 ll -152.2066 kl 0.2647 sf 1830.4929 selected 0.2942\n",
      "\n",
      "# epoch 119 iter 10200: dev loss -1596.2312 elbo 1596.2312 ll -147.1904 kl 0.2850 sf 1743.7065 selected 0.2997 acc 0.3361\n",
      " dev0 [gold=3,pred=4]: it **'s** a **lovely** **film** **with** **lovely** performances **by** **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , which **is** **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're not nearly moved to **tears** by a couple of scenes **,** **you** 've got ice water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 120 iter 10285: dev loss -1552.6301 elbo 1552.6301 ll -145.6023 kl 0.2135 sf 1698.4459 selected 0.2935 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=1]: **no** one **goes** unindicted here , **which** **is** **probably** **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to **tears** by **a** couple of scenes **,** you 've got ice water in your veins .\n",
      "\n",
      "Epoch 121 Iter 10300 loss=-1559.4154 elbo 1509.6254 ll -148.6271 kl 0.1131 sf 1658.3658 selected 0.2845\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 121 iter 10370: dev loss -1574.4271 elbo 1574.4271 ll -147.0145 kl 0.1076 sf 1721.5492 selected 0.2964 acc 0.3433\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film with **lovely** **performances** by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** , **which** **is** probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to tears by a couple **of** scenes , you 've got ice **water** **in** your veins .\n",
      "\n",
      "Epoch 122 Iter 10400 loss=-1566.5791 elbo 1631.4677 ll -150.1225 kl 0.2312 sf 1781.8213 selected 0.3186\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 122 iter 10455: dev loss -1564.3048 elbo 1564.3048 ll -146.4919 kl 0.3327 sf 1711.1295 selected 0.2929 acc 0.3524\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here **,** which is **probably** **for** **the** best **.**\n",
      " dev2 [gold=3,pred=3]: **and** if **you** **'re** **not** nearly moved to tears **by** **a** **couple** of **scenes** **,** you **'ve** got ice water in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 123 Iter 10500 loss=-1565.7129 elbo 1523.9021 ll -145.9797 kl 0.2658 sf 1670.1475 selected 0.2891\n",
      "\n",
      "# epoch 123 iter 10540: dev loss -1566.3511 elbo 1566.3511 ll -146.1208 kl 0.0808 sf 1712.5527 selected 0.2950 acc 0.3397\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , **which** **is** probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're not nearly moved **to** **tears** by **a** couple **of** scenes , you 've got **ice** water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 124 Iter 10600 loss=-1553.6271 elbo 1577.7010 ll -147.6734 kl 0.1783 sf 1725.5527 selected 0.2713\n",
      "\n",
      "# epoch 124 iter 10625: dev loss -1576.1606 elbo 1576.1606 ll -145.4279 kl 0.1043 sf 1721.6927 selected 0.3029 acc 0.3488\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** with **lovely** performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , which **is** probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved to tears by a **couple** **of** scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 125 Iter 10700 loss=-1559.2504 elbo 1808.6091 ll -155.4305 kl 0.0699 sf 1964.1093 selected 0.3179\n",
      "\n",
      "# epoch 125 iter 10710: dev loss -1578.1564 elbo 1578.1564 ll -145.7411 kl 0.1425 sf 1724.0400 selected 0.2996 acc 0.3451\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a lovely **film** with lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes **unindicted** here , which is **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not **nearly** moved to tears by a couple of scenes **,** you 've got ice water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 126 iter 10795: dev loss -1582.0490 elbo 1582.0490 ll -146.3838 kl 0.3820 sf 1728.8148 selected 0.2984 acc 0.3243\n",
      " dev0 [gold=3,pred=3]: it 's **a** **lovely** **film** with lovely performances **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which **is** probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not **nearly** **moved** to tears by **a** couple **of** **scenes** , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 127 Iter 10800 loss=-1549.9254 elbo 1497.8177 ll -141.0865 kl 0.0734 sf 1638.9779 selected 0.2978\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 127 iter 10880: dev loss -1569.9346 elbo 1569.9346 ll -145.4574 kl 0.0542 sf 1715.4462 selected 0.2977 acc 0.3361\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here , which is probably **for** the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you **'re** not nearly moved to tears by **a** couple **of** scenes **,** **you** 've got ice water in **your** veins .\n",
      "\n",
      "Epoch 128 Iter 10900 loss=-1553.8195 elbo 1469.5070 ll -144.4686 kl 0.0870 sf 1614.0630 selected 0.2839\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 128 iter 10965: dev loss -1558.0127 elbo 1558.0127 ll -145.4898 kl 0.1788 sf 1703.6813 selected 0.2997 acc 0.3724\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film **with** **lovely** **performances** **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , **which** is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved **to** tears by a couple **of** **scenes** , **you** **'ve** got **ice** water in your veins .\n",
      "\n",
      "Epoch 129 Iter 11000 loss=-1567.9279 elbo 1580.2719 ll -149.0724 kl 0.1761 sf 1729.5203 selected 0.3064\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 129 iter 11050: dev loss -1581.7764 elbo 1581.7764 ll -144.5926 kl 0.1387 sf 1726.5077 selected 0.3085 acc 0.3579\n",
      " dev0 [gold=3,pred=4]: **it** **'s** a lovely film with lovely **performances** by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted **here** , which is probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not nearly **moved** to **tears** by **a** couple **of** **scenes** , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 130 Iter 11100 loss=-1535.0826 elbo 1577.5857 ll -152.8926 kl 0.3745 sf 1730.8528 selected 0.2828\n",
      "\n",
      "# epoch 130 iter 11135: dev loss -1571.9158 elbo 1571.9158 ll -146.0074 kl 0.2100 sf 1718.1333 selected 0.3002 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** film with lovely performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** unindicted here , which **is** probably for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not **nearly** **moved** to tears by a **couple** **of** scenes , you 've got ice **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 131 Iter 11200 loss=-1568.1685 elbo 1559.1649 ll -157.2719 kl 0.1852 sf 1716.6221 selected 0.3044\n",
      "\n",
      "# epoch 131 iter 11220: dev loss -1574.5065 elbo 1574.5065 ll -144.9480 kl 0.1297 sf 1719.5842 selected 0.3012 acc 0.3678\n",
      " dev0 [gold=3,pred=4]: it **'s** **a** **lovely** film with lovely performances **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , which is **probably** for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** **'re** not nearly **moved** to tears **by** a couple **of** **scenes** **,** **you** **'ve** got ice water **in** your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 132 Iter 11300 loss=-1561.0955 elbo 1509.7418 ll -149.8568 kl 0.0272 sf 1659.6259 selected 0.2878\n",
      "\n",
      "# epoch 132 iter 11305: dev loss -1592.8113 elbo 1592.8113 ll -146.2830 kl 0.1439 sf 1739.2382 selected 0.3029 acc 0.3542\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film **with** **lovely** **performances** by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , **which** is **probably** **for** the **best** .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly **moved** to tears by a couple **of** scenes , you **'ve** got ice water in **your** **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 133 iter 11390: dev loss -1595.8060 elbo 1595.8060 ll -146.0932 kl 0.0939 sf 1741.9932 selected 0.3054 acc 0.3651\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** **'re** not nearly **moved** to tears **by** a **couple** of scenes , **you** 've **got** **ice** water in your veins .\n",
      "\n",
      "Epoch 134 Iter 11400 loss=-1550.7698 elbo 1664.8619 ll -146.5698 kl 0.0994 sf 1811.5310 selected 0.3080\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 134 iter 11475: dev loss -1553.6393 elbo 1553.6393 ll -143.8933 kl 0.3402 sf 1697.8727 selected 0.3023 acc 0.3624\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film **with** lovely performances by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted **here** , which is probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** **you** **'re** **not** nearly moved to tears by a couple **of** scenes , you 've **got** **ice** **water** **in** your veins .\n",
      "\n",
      "Epoch 135 Iter 11500 loss=-1556.5879 elbo 1603.0033 ll -148.8145 kl 0.1051 sf 1751.9230 selected 0.2998\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 135 iter 11560: dev loss -1573.3620 elbo 1573.3620 ll -146.6664 kl -0.0009 sf 1720.0275 selected 0.2977 acc 0.3424\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly moved **to** tears by a couple of scenes , you **'ve** got ice **water** in **your** veins .\n",
      "\n",
      "Epoch 136 Iter 11600 loss=-1561.1075 elbo 1685.6580 ll -155.0229 kl 0.1527 sf 1840.8336 selected 0.3137\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 136 iter 11645: dev loss -1589.6308 elbo 1589.6308 ll -147.0484 kl 0.0905 sf 1736.7697 selected 0.3051 acc 0.3279\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a **lovely** film with **lovely** **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly moved to tears by a couple of scenes **,** you **'ve** **got** **ice** water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 137 Iter 11700 loss=-1545.5530 elbo 1715.0511 ll -145.9638 kl 0.2784 sf 1861.2935 selected 0.3172\n",
      "\n",
      "# epoch 137 iter 11730: dev loss -1565.5192 elbo 1565.5192 ll -145.1854 kl 0.2607 sf 1710.9653 selected 0.2997 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: it **'s** a **lovely** film with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here **,** **which** is **probably** for the best .\n",
      " dev2 [gold=3,pred=1]: and if **you** 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 138 Iter 11800 loss=-1556.9975 elbo 1762.6885 ll -146.4379 kl 0.4614 sf 1909.5875 selected 0.3078\n",
      "\n",
      "# epoch 138 iter 11815: dev loss -1582.6335 elbo 1582.6335 ll -146.3347 kl 0.2865 sf 1729.2546 selected 0.3017 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: **no** one goes unindicted here , which is probably **for** **the** **best** .\n",
      " dev2 [gold=3,pred=3]: and **if** you **'re** **not** nearly moved to **tears** by a couple of scenes , you **'ve** got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 139 Iter 11900 loss=-1564.2302 elbo 1848.0441 ll -153.3323 kl 0.2923 sf 2001.6686 selected 0.3198\n",
      "\n",
      "# epoch 139 iter 11900: dev loss -1570.1546 elbo 1570.1546 ll -146.1891 kl 0.1378 sf 1716.4814 selected 0.2992 acc 0.3379\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** **lovely** **film** with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes **unindicted** here **,** which **is** **probably** **for** the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to tears by a **couple** **of** **scenes** **,** you **'ve** got ice **water** **in** your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 140 iter 11985: dev loss -1555.8207 elbo 1555.8207 ll -146.2763 kl 0.1131 sf 1702.2101 selected 0.2914 acc 0.3515\n",
      " dev0 [gold=3,pred=4]: it 's a lovely film with lovely performances **by** buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , which is probably for **the** **best** .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** **nearly** **moved** to tears by a couple of scenes , you **'ve** got ice water in **your** veins .\n",
      "\n",
      "Epoch 141 Iter 12000 loss=-1549.3239 elbo 1467.7515 ll -143.7067 kl 0.2833 sf 1611.7415 selected 0.2781\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 141 iter 12070: dev loss -1561.2888 elbo 1561.2888 ll -145.0154 kl 0.2833 sf 1706.5876 selected 0.2989 acc 0.3569\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely **film** with **lovely** **performances** by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** , which **is** **probably** for the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're **not** nearly **moved** to tears by a **couple** **of** scenes , you 've **got** ice **water** **in** **your** **veins** .\n",
      "\n",
      "Epoch 142 Iter 12100 loss=-1558.9385 elbo 1464.5409 ll -147.6355 kl 0.2261 sf 1612.4026 selected 0.2719\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 142 iter 12155: dev loss -1570.7804 elbo 1570.7804 ll -145.3099 kl 0.0114 sf 1716.1017 selected 0.3021 acc 0.3379\n",
      " dev0 [gold=3,pred=4]: it 's a lovely film with lovely performances **by** **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes **unindicted** here , which is **probably** **for** **the** best **.**\n",
      " dev2 [gold=3,pred=3]: **and** if **you** 're not nearly moved to tears by a **couple** of scenes **,** you 've got ice water in your veins .\n",
      "\n",
      "Epoch 143 Iter 12200 loss=-1575.0376 elbo 1527.9999 ll -152.1902 kl 0.1226 sf 1680.3130 selected 0.2864\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 143 iter 12240: dev loss -1584.3139 elbo 1584.3139 ll -146.2572 kl 0.1677 sf 1730.7388 selected 0.3012 acc 0.3361\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** with **lovely** performances **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're **not** **nearly** **moved** to tears by **a** couple of scenes , you 've got ice **water** in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 144 Iter 12300 loss=-1549.1674 elbo 1736.3752 ll -152.0341 kl 0.3109 sf 1888.7202 selected 0.3175\n",
      "\n",
      "# epoch 144 iter 12325: dev loss -1547.0067 elbo 1547.0067 ll -144.7718 kl 0.3747 sf 1692.1533 selected 0.2987 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly **moved** **to** **tears** by a couple of scenes **,** you 've got **ice** water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 145 Iter 12400 loss=-1550.2992 elbo 1614.4200 ll -152.4915 kl 0.2018 sf 1767.1132 selected 0.3072\n",
      "\n",
      "# epoch 145 iter 12410: dev loss -1589.4959 elbo 1589.4959 ll -146.2031 kl 0.0985 sf 1735.7976 selected 0.3036 acc 0.3297\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** **lovely** film **with** lovely performances by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** **here** **,** which is probably for **the** **best** .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved **to** tears **by** **a** couple of scenes , **you** **'ve** **got** ice water in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 146 iter 12495: dev loss -1571.3087 elbo 1571.3087 ll -145.3754 kl 0.0800 sf 1716.7642 selected 0.3034 acc 0.3542\n",
      " dev0 [gold=3,pred=4]: it 's **a** lovely **film** with **lovely** performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** **here** , **which** is **probably** for the **best** .\n",
      " dev2 [gold=3,pred=3]: and if **you** **'re** not **nearly** moved **to** **tears** by **a** couple of scenes **,** you 've got ice **water** in your **veins** .\n",
      "\n",
      "Epoch 147 Iter 12500 loss=-1553.7597 elbo 1533.0314 ll -146.8798 kl 0.3370 sf 1680.2482 selected 0.2893\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 147 iter 12580: dev loss -1572.2526 elbo 1572.2526 ll -145.1366 kl 0.2807 sf 1717.6700 selected 0.3024 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely **performances** by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** unindicted here , which is probably **for** the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to tears by **a** **couple** of scenes , **you** 've got **ice** water **in** your veins .\n",
      "\n",
      "Epoch 148 Iter 12600 loss=-1560.1771 elbo 1742.2161 ll -156.7539 kl 0.3699 sf 1899.3398 selected 0.2940\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 148 iter 12665: dev loss -1571.2286 elbo 1571.2286 ll -147.0061 kl 0.1920 sf 1718.4268 selected 0.2930 acc 0.3569\n",
      " dev0 [gold=3,pred=4]: it 's a lovely film with **lovely** performances by **buy** and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** **you** 're not nearly moved **to** **tears** by a **couple** **of** **scenes** , you 've got **ice** water in your **veins** .\n",
      "\n",
      "Epoch 149 Iter 12700 loss=-1565.8404 elbo 1710.4899 ll -142.4019 kl 0.1312 sf 1853.0232 selected 0.3038\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 149 iter 12750: dev loss -1588.0273 elbo 1588.0273 ll -145.0746 kl 0.1355 sf 1733.2374 selected 0.3081 acc 0.3697\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film with lovely performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** unindicted here , which **is** **probably** **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if you **'re** **not** nearly moved to **tears** **by** **a** couple of scenes , you 've got ice **water** in your veins .\n",
      "\n",
      "Epoch 150 Iter 12800 loss=-1565.3409 elbo 1604.7629 ll -153.0837 kl 0.3490 sf 1758.1958 selected 0.2928\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 150 iter 12835: dev loss -1586.7639 elbo 1586.7639 ll -146.9467 kl 0.0931 sf 1733.8036 selected 0.2990 acc 0.3351\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes **unindicted** here , which is **probably** for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved **to** **tears** by a **couple** **of** scenes , you 've got **ice** water **in** your **veins** .\n",
      "\n",
      "Epoch 151 Iter 12900 loss=-1554.8493 elbo 636.5146 ll -61.4922 kl 0.0373 sf 698.0443 selected 0.3076\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 151 iter 12920: dev loss -1577.5606 elbo 1577.5606 ll -146.2627 kl 0.1050 sf 1723.9283 selected 0.2983 acc 0.3451\n",
      " dev0 [gold=3,pred=4]: it **'s** a **lovely** **film** with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , **which** is probably **for** the best .\n",
      " dev2 [gold=3,pred=1]: and **if** you 're **not** **nearly** moved to **tears** **by** **a** couple of scenes , **you** **'ve** got ice water in **your** **veins** **.**\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 152 Iter 13000 loss=-1552.4642 elbo 1672.2776 ll -159.0174 kl 0.1600 sf 1831.4551 selected 0.2920\n",
      "\n",
      "# epoch 152 iter 13005: dev loss -1571.8888 elbo 1571.8888 ll -146.2724 kl 0.2864 sf 1718.4477 selected 0.2977 acc 0.3488\n",
      " dev0 [gold=3,pred=4]: it 's **a** **lovely** film with lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted **here** , which **is** probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly moved to **tears** **by** a couple of **scenes** **,** you **'ve** got ice water **in** **your** veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 153 iter 13090: dev loss -1579.4933 elbo 1579.4933 ll -146.0185 kl 0.2165 sf 1725.7284 selected 0.2998 acc 0.3406\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** **with** lovely performances **by** buy and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** here **,** which **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a **couple** of **scenes** , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 154 Iter 13100 loss=-1552.5843 elbo 1542.1721 ll -153.0781 kl 0.4347 sf 1695.6851 selected 0.3076\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 154 iter 13175: dev loss -1583.6725 elbo 1583.6725 ll -145.7585 kl 0.1646 sf 1729.5956 selected 0.3029 acc 0.3397\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** with lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which **is** **probably** **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly moved to **tears** by a **couple** of scenes , you **'ve** got ice **water** in your veins .\n",
      "\n",
      "Epoch 155 Iter 13200 loss=-1563.6972 elbo 1664.0409 ll -150.3568 kl 0.1761 sf 1814.5736 selected 0.2811\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 155 iter 13260: dev loss -1564.4976 elbo 1564.4976 ll -144.9635 kl -0.0279 sf 1709.4333 selected 0.3013 acc 0.3506\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here , **which** **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: **and** if you **'re** **not** **nearly** moved **to** tears **by** **a** couple **of** **scenes** **,** you 've got ice **water** in your **veins** .\n",
      "\n",
      "Epoch 156 Iter 13300 loss=-1558.2915 elbo 1504.4979 ll -144.6105 kl 0.1095 sf 1649.2178 selected 0.2990\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 156 iter 13345: dev loss -1582.0752 elbo 1582.0752 ll -145.9092 kl 0.1829 sf 1728.1672 selected 0.3013 acc 0.3479\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** **film** **with** **lovely** performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes **unindicted** **here** , which **is** **probably** **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to tears by **a** couple of scenes **,** **you** 've got ice water in your veins **.**\n",
      "\n",
      "Epoch 157 Iter 13400 loss=-1570.2085 elbo 1374.8392 ll -141.5534 kl 0.1148 sf 1516.5076 selected 0.2995\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 157 iter 13430: dev loss -1584.4011 elbo 1584.4011 ll -145.7771 kl 0.1602 sf 1730.3384 selected 0.3014 acc 0.3642\n",
      " dev0 [gold=3,pred=4]: **it** **'s** a **lovely** film **with** lovely performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here **,** **which** is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly **moved** to tears by a couple of scenes , you 've got **ice** **water** **in** your veins **.**\n",
      "\n",
      "Epoch 158 Iter 13500 loss=-1556.1222 elbo 1425.5399 ll -140.6720 kl 0.2299 sf 1566.4419 selected 0.3080\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 158 iter 13515: dev loss -1603.4565 elbo 1603.4565 ll -148.0424 kl 0.1033 sf 1751.6022 selected 0.2987 acc 0.3424\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film **with** lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** **,** which is probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly **moved** to **tears** **by** a couple of **scenes** , **you** **'ve** got ice **water** in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 159 Iter 13600 loss=-1558.7752 elbo 1448.6400 ll -142.8831 kl 0.3809 sf 1591.9041 selected 0.2781\n",
      "\n",
      "# epoch 159 iter 13600: dev loss -1583.4714 elbo 1583.4714 ll -146.2363 kl 0.1047 sf 1729.8123 selected 0.3022 acc 0.3524\n",
      " dev0 [gold=3,pred=4]: it 's a lovely **film** **with** lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved to tears **by** a couple of **scenes** **,** you 've got **ice** water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 160 iter 13685: dev loss -1572.8505 elbo 1572.8505 ll -145.4712 kl 0.2069 sf 1718.5287 selected 0.3012 acc 0.3569\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely **film** with lovely performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which is probably **for** the best **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're **not** nearly moved to tears by **a** couple of scenes , you 've got **ice** **water** in your **veins** .\n",
      "\n",
      "Epoch 161 Iter 13700 loss=-1552.8427 elbo 1581.2074 ll -139.3661 kl 0.3474 sf 1720.9210 selected 0.2904\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 161 iter 13770: dev loss -1576.8641 elbo 1576.8641 ll -144.8770 kl 0.1264 sf 1721.8676 selected 0.3011 acc 0.3506\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a lovely film with **lovely** performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** unindicted here , which **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're not nearly moved to tears by a **couple** of scenes , you 've **got** **ice** **water** in your veins **.**\n",
      "\n",
      "Epoch 162 Iter 13800 loss=-1548.7928 elbo 1602.0432 ll -151.1965 kl 0.5115 sf 1753.7513 selected 0.2998\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 162 iter 13855: dev loss -1580.4412 elbo 1580.4412 ll -145.7924 kl -0.0037 sf 1726.2299 selected 0.3019 acc 0.3560\n",
      " dev0 [gold=3,pred=1]: it 's **a** lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted **here** , which **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not **nearly** moved to tears by a couple **of** scenes , you 've got ice **water** **in** **your** veins .\n",
      "\n",
      "Epoch 163 Iter 13900 loss=-1564.0333 elbo 1660.8478 ll -149.5571 kl 0.0054 sf 1810.4102 selected 0.2857\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 163 iter 13940: dev loss -1609.4583 elbo 1609.4583 ll -147.5382 kl 0.2093 sf 1757.2058 selected 0.2991 acc 0.3333\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely **film** with lovely **performances** by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which is probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to **tears** **by** a couple of scenes , you **'ve** got ice **water** in your veins **.**\n",
      "\n",
      "Epoch 164 Iter 14000 loss=-1541.0375 elbo 1478.4222 ll -148.6723 kl 0.2226 sf 1627.3171 selected 0.3011\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 164 iter 14025: dev loss -1567.6083 elbo 1567.6083 ll -146.2187 kl 0.4400 sf 1714.2670 selected 0.2978 acc 0.3388\n",
      " dev0 [gold=3,pred=4]: **it** **'s** a lovely **film** with **lovely** performances by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , which **is** probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're **not** nearly moved **to** tears by a couple **of** scenes **,** you **'ve** got ice water in your **veins** .\n",
      "\n",
      "Epoch 165 Iter 14100 loss=-1564.4846 elbo 1469.1627 ll -142.5827 kl 0.1774 sf 1611.9227 selected 0.2906\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 165 iter 14110: dev loss -1609.3565 elbo 1609.3565 ll -148.0841 kl 0.1473 sf 1757.5878 selected 0.3004 acc 0.3252\n",
      " dev0 [gold=3,pred=4]: **it** 's **a** lovely film **with** **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** **here** **,** which is **probably** for the best **.**\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly **moved** to **tears** by **a** couple **of** **scenes** **,** **you** 've got ice water in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 166 iter 14195: dev loss -1577.9037 elbo 1577.9037 ll -146.0494 kl -0.0350 sf 1723.9182 selected 0.2983 acc 0.3597\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here **,** which **is** probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're not nearly moved to tears by a **couple** of **scenes** , you 've got **ice** water **in** your **veins** .\n",
      "\n",
      "Epoch 167 Iter 14200 loss=-1564.4951 elbo 1498.8346 ll -149.8576 kl 0.3061 sf 1648.9982 selected 0.2932\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 167 iter 14280: dev loss -1597.5578 elbo 1597.5578 ll -146.7439 kl 0.0815 sf 1744.3832 selected 0.3049 acc 0.3606\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely **performances** **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you **'re** **not** nearly moved to **tears** by **a** **couple** of scenes , **you** 've got ice **water** in your **veins** **.**\n",
      "\n",
      "Epoch 168 Iter 14300 loss=-1561.8690 elbo 1849.3557 ll -159.8885 kl 0.3963 sf 2009.6404 selected 0.3034\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 168 iter 14365: dev loss -1565.3045 elbo 1565.3045 ll -145.5612 kl 0.3350 sf 1711.2008 selected 0.2996 acc 0.3533\n",
      " dev0 [gold=3,pred=1]: **it** **'s** a lovely film with **lovely** performances by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which is probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly moved to tears **by** a couple of scenes , you 've **got** ice water in **your** veins .\n",
      "\n",
      "Epoch 169 Iter 14400 loss=-1554.2859 elbo 1441.4972 ll -140.7468 kl 0.0657 sf 1582.3094 selected 0.2743\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 169 iter 14450: dev loss -1567.8602 elbo 1567.8602 ll -145.3786 kl 0.1710 sf 1713.4098 selected 0.3027 acc 0.3633\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with lovely **performances** by **buy** **and** **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , **which** **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly moved **to** tears by a **couple** of scenes **,** **you** 've got **ice** water **in** your veins .\n",
      "\n",
      "Epoch 170 Iter 14500 loss=-1556.6456 elbo 1719.8855 ll -144.8264 kl 0.2297 sf 1864.9420 selected 0.3039\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 170 iter 14535: dev loss -1567.4622 elbo 1567.4622 ll -145.2253 kl 0.0683 sf 1712.7558 selected 0.3038 acc 0.3397\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a lovely film **with** lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** **which** is **probably** for the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly **moved** **to** tears by a **couple** of scenes **,** you **'ve** got ice **water** in your veins .\n",
      "\n",
      "Epoch 171 Iter 14600 loss=-1555.4654 elbo 1626.0756 ll -151.7534 kl -0.0048 sf 1777.8241 selected 0.3108\n",
      "\n",
      "# epoch 171 iter 14620: dev loss -1580.7450 elbo 1580.7450 ll -146.7853 kl 0.1313 sf 1727.6616 selected 0.2986 acc 0.3460\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here **,** which **is** **probably** **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not **nearly** **moved** to tears by a **couple** of scenes , **you** **'ve** **got** **ice** water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 172 Iter 14700 loss=-1570.9223 elbo 1365.2827 ll -149.3413 kl 0.0480 sf 1514.6720 selected 0.2943\n",
      "\n",
      "# epoch 172 iter 14705: dev loss -1602.2733 elbo 1602.2733 ll -147.2458 kl 0.1277 sf 1749.6468 selected 0.3016 acc 0.3424\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with lovely performances **by** **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted **here** , **which** is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** **you** **'re** **not** nearly **moved** to tears **by** a couple of **scenes** **,** **you** **'ve** got ice water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 173 iter 14790: dev loss -1587.1946 elbo 1587.1946 ll -145.7292 kl 0.3631 sf 1733.2869 selected 0.3020 acc 0.3660\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted **here** , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** **to** **tears** by **a** **couple** **of** scenes , you 've **got** **ice** water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 174 Iter 14800 loss=-1552.1727 elbo 1699.7336 ll -151.5764 kl 0.3388 sf 1851.6490 selected 0.3087\n",
      "\n",
      "# epoch 174 iter 14875: dev loss -1588.9620 elbo 1588.9620 ll -146.1157 kl 0.0903 sf 1735.1680 selected 0.3004 acc 0.3397\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted **here** , which is **probably** **for** the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly moved **to** tears by a **couple** of scenes , **you** **'ve** got **ice** water in your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 175 Iter 14900 loss=-1549.3203 elbo 1644.0073 ll -148.8597 kl 0.2733 sf 1793.1404 selected 0.2853\n",
      "\n",
      "# epoch 175 iter 14960: dev loss -1593.6457 elbo 1593.6457 ll -147.1575 kl 0.1582 sf 1740.9615 selected 0.3012 acc 0.3433\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** lovely film with **lovely** **performances** by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which **is** probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: **and** if you **'re** not nearly moved to **tears** by **a** **couple** of **scenes** , you 've **got** ice **water** in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 176 Iter 15000 loss=-1552.8359 elbo 1529.3065 ll -146.2666 kl 0.1358 sf 1675.7089 selected 0.2958\n",
      "\n",
      "# epoch 176 iter 15045: dev loss -1571.7719 elbo 1571.7719 ll -146.7060 kl 0.3812 sf 1718.8592 selected 0.3015 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely **film** **with** lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** unindicted **here** , **which** is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: and **if** you **'re** not nearly **moved** **to** tears **by** a couple of scenes , you **'ve** **got** **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 177 Iter 15100 loss=-1559.1419 elbo 1435.2665 ll -143.7365 kl 0.1913 sf 1579.1942 selected 0.2859\n",
      "\n",
      "# epoch 177 iter 15130: dev loss -1570.4124 elbo 1570.4124 ll -146.4702 kl 0.1703 sf 1717.0529 selected 0.2980 acc 0.3424\n",
      " dev0 [gold=3,pred=1]: **it** **'s** a **lovely** film with lovely **performances** **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , which is **probably** for the best **.**\n",
      " dev2 [gold=3,pred=3]: **and** if **you** 're not **nearly** moved to **tears** by **a** **couple** of scenes , you **'ve** got **ice** water **in** **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 178 Iter 15200 loss=-1552.8997 elbo 1519.8346 ll -147.0853 kl 0.3995 sf 1667.3193 selected 0.2828\n",
      "\n",
      "# epoch 178 iter 15215: dev loss -1589.2220 elbo 1589.2220 ll -146.4211 kl 0.3691 sf 1736.0121 selected 0.3011 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely **film** **with** lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** **,** which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not **nearly** moved to tears **by** **a** couple of **scenes** , you 've got ice water in **your** veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 179 Iter 15300 loss=-1570.0439 elbo 1523.4706 ll -150.4683 kl 0.1265 sf 1674.0653 selected 0.2707\n",
      "\n",
      "# epoch 179 iter 15300: dev loss -1586.1854 elbo 1586.1854 ll -146.5841 kl 0.1476 sf 1732.9170 selected 0.3030 acc 0.3479\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** lovely film **with** **lovely** **performances** **by** **buy** and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here **,** which **is** **probably** for **the** **best** .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved to tears by a couple of scenes , **you** 've got ice water **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# epoch 180 iter 15385: dev loss -1574.3370 elbo 1574.3370 ll -145.6691 kl 0.1648 sf 1720.1710 selected 0.2984 acc 0.3669\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film with **lovely** performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no **one** goes unindicted here , which is probably for **the** best **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly **moved** to **tears** by **a** couple of scenes **,** you 've **got** ice water **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 181 Iter 15400 loss=-1539.0535 elbo 1598.6377 ll -151.7061 kl 0.0549 sf 1750.3987 selected 0.3164\n",
      "\n",
      "# epoch 181 iter 15470: dev loss -1590.3775 elbo 1590.3775 ll -146.4939 kl 0.1228 sf 1736.9943 selected 0.3024 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: it 's **a** **lovely** film with lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** which is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved to tears **by** a couple of **scenes** , you 've got ice water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 182 Iter 15500 loss=-1555.5313 elbo 1528.8624 ll -148.6579 kl 0.1346 sf 1677.6548 selected 0.2978\n",
      "\n",
      "# epoch 182 iter 15555: dev loss -1576.2321 elbo 1576.2321 ll -146.5188 kl 0.0876 sf 1722.8385 selected 0.2944 acc 0.3397\n",
      " dev0 [gold=3,pred=1]: **it** 's a lovely film with lovely performances **by** **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which **is** **probably** **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved **to** tears by **a** couple of scenes **,** you 've got **ice** water in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 183 Iter 15600 loss=-1556.7224 elbo 1870.6251 ll -154.7178 kl 0.1369 sf 2025.4797 selected 0.3331\n",
      "\n",
      "# epoch 183 iter 15640: dev loss -1591.9825 elbo 1591.9825 ll -146.3161 kl 0.3684 sf 1738.6669 selected 0.3075 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a lovely **film** **with** **lovely** performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** which **is** probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** **nearly** moved to **tears** **by** **a** couple **of** scenes **,** **you** 've got **ice** water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 184 Iter 15700 loss=-1564.9383 elbo 1556.6847 ll -145.0656 kl 0.0875 sf 1701.8378 selected 0.3041\n",
      "\n",
      "# epoch 184 iter 15725: dev loss -1563.2498 elbo 1563.2498 ll -145.0816 kl 0.0238 sf 1708.3552 selected 0.2999 acc 0.3569\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a lovely film with lovely performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , **which** is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you **'re** **not** nearly **moved** **to** **tears** **by** **a** couple **of** scenes **,** you 've got ice water in your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 185 Iter 15800 loss=-1558.5638 elbo 1445.2782 ll -143.4098 kl 0.1784 sf 1588.8662 selected 0.3127\n",
      "\n",
      "# epoch 185 iter 15810: dev loss -1607.1475 elbo 1607.1475 ll -147.2957 kl 0.1461 sf 1754.5894 selected 0.3033 acc 0.3588\n",
      " dev0 [gold=3,pred=4]: **it** 's a lovely **film** with lovely performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** **unindicted** here , which is probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not nearly moved to tears by **a** **couple** of scenes , you 've **got** ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 186 iter 15895: dev loss -1611.8395 elbo 1611.8395 ll -147.0359 kl 0.3358 sf 1759.2111 selected 0.3094 acc 0.3542\n",
      " dev0 [gold=3,pred=4]: **it** **'s** a lovely film **with** **lovely** performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted **here** **,** which is probably **for** **the** **best** .\n",
      " dev2 [gold=3,pred=3]: **and** if **you** 're **not** **nearly** moved to tears by a couple **of** scenes , you 've **got** ice water in your **veins** .\n",
      "\n",
      "Epoch 187 Iter 15900 loss=-1554.0103 elbo 1624.8895 ll -150.8008 kl 0.2501 sf 1775.9406 selected 0.2812\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 187 iter 15980: dev loss -1579.2768 elbo 1579.2768 ll -147.2392 kl 0.1931 sf 1726.7091 selected 0.2975 acc 0.3361\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which **is** probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if **you** **'re** not nearly moved **to** **tears** **by** **a** couple **of** scenes **,** you 've got ice water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 188 Iter 16000 loss=-1553.9871 elbo 1528.7194 ll -142.3128 kl 0.0769 sf 1671.1091 selected 0.3055\n",
      "\n",
      "# epoch 188 iter 16065: dev loss -1566.7221 elbo 1566.7221 ll -145.5879 kl 0.3729 sf 1712.6828 selected 0.2992 acc 0.3542\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with lovely performances **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , which is **probably** **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not nearly **moved** to tears by **a** **couple** of scenes , you **'ve** got **ice** water in **your** veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 189 Iter 16100 loss=-1565.5802 elbo 1673.6829 ll -153.2511 kl 0.4548 sf 1827.3888 selected 0.2829\n",
      "\n",
      "# epoch 189 iter 16150: dev loss -1582.5710 elbo 1582.5710 ll -145.1117 kl 0.1875 sf 1727.8703 selected 0.3032 acc 0.3533\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film **with** lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** here **,** which **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to **tears** by **a** couple of scenes **,** you **'ve** **got** ice water in your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 190 Iter 16200 loss=-1558.0095 elbo 1557.0208 ll -140.7188 kl 0.3066 sf 1698.0463 selected 0.2990\n",
      "\n",
      "# epoch 190 iter 16235: dev loss -1594.7421 elbo 1594.7421 ll -147.2590 kl 0.0501 sf 1742.0512 selected 0.3038 acc 0.3370\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with **lovely** **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which **is** **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not nearly moved to tears **by** **a** couple of scenes **,** you 've got **ice** water **in** **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 191 Iter 16300 loss=-1544.4912 elbo 1463.5220 ll -144.8229 kl 0.2496 sf 1608.5944 selected 0.2657\n",
      "\n",
      "# epoch 191 iter 16320: dev loss -1592.4226 elbo 1592.4226 ll -147.4908 kl 0.1282 sf 1740.0414 selected 0.2985 acc 0.3261\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film **with** **lovely** performances **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** unindicted here , **which** is **probably** for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved **to** **tears** by a **couple** of scenes , **you** 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 192 Iter 16400 loss=-1561.2718 elbo 1441.4954 ll -137.4663 kl -0.0018 sf 1578.9600 selected 0.3071\n",
      "\n",
      "# epoch 192 iter 16405: dev loss -1579.8395 elbo 1579.8395 ll -146.8809 kl 0.0856 sf 1726.8060 selected 0.3009 acc 0.3470\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film **with** lovely performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** here , which **is** probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to tears **by** **a** **couple** of **scenes** , **you** 've got **ice** water in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 193 iter 16490: dev loss -1578.0150 elbo 1578.0150 ll -145.1811 kl 0.1977 sf 1723.3938 selected 0.3024 acc 0.3624\n",
      " dev0 [gold=3,pred=4]: **it** 's a lovely **film** with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted **here** **,** **which** is probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you **'re** not nearly **moved** **to** tears by a couple of **scenes** , you 've got **ice** **water** **in** your veins .\n",
      "\n",
      "Epoch 194 Iter 16500 loss=-1574.7333 elbo 1589.6772 ll -150.1512 kl 0.2195 sf 1740.0477 selected 0.2886\n",
      "Shuffling training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# epoch 194 iter 16575: dev loss -1561.5185 elbo 1561.5185 ll -145.3706 kl 0.0798 sf 1706.9689 selected 0.2996 acc 0.3506\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a **lovely** film with lovely performances by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , **which** is probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and if you **'re** not **nearly** **moved** to tears by a couple of scenes , **you** 've **got** **ice** water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 195 Iter 16600 loss=-1547.4916 elbo 1511.6003 ll -150.9410 kl 0.0573 sf 1662.5986 selected 0.3238\n",
      "\n",
      "# epoch 195 iter 16660: dev loss -1580.0646 elbo 1580.0646 ll -146.0641 kl 0.3022 sf 1726.4309 selected 0.3022 acc 0.3524\n",
      " dev0 [gold=3,pred=4]: it 's a lovely film with **lovely** **performances** by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no **one** goes **unindicted** **here** **,** which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're **not** **nearly** moved to tears by **a** **couple** of scenes , you 've got ice **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 196 Iter 16700 loss=-1551.7828 elbo 1507.6696 ll -151.7404 kl 0.0724 sf 1659.4824 selected 0.2912\n",
      "\n",
      "# epoch 196 iter 16745: dev loss -1577.6646 elbo 1577.6646 ll -146.2797 kl 0.1741 sf 1724.1183 selected 0.2987 acc 0.3315\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film with lovely performances **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** unindicted here **,** which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved to tears **by** a couple of scenes **,** you 've got ice **water** in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 197 Iter 16800 loss=-1562.3539 elbo 1786.8464 ll -156.7961 kl 0.0013 sf 1943.6437 selected 0.3148\n",
      "\n",
      "# epoch 197 iter 16830: dev loss -1592.0851 elbo 1592.0851 ll -146.8029 kl -0.0492 sf 1738.8388 selected 0.3030 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film **with** lovely performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly moved **to** tears by a **couple** of **scenes** , you **'ve** got **ice** **water** **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 198 Iter 16900 loss=-1570.5998 elbo 1592.0129 ll -144.8221 kl 0.1822 sf 1737.0171 selected 0.3183\n",
      "\n",
      "# epoch 198 iter 16915: dev loss -1599.5111 elbo 1599.5111 ll -146.5945 kl 0.0514 sf 1746.1570 selected 0.3064 acc 0.3488\n",
      " dev0 [gold=3,pred=3]: it 's **a** **lovely** film with lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here , which is probably **for** the best **.**\n",
      " dev2 [gold=3,pred=3]: **and** if you **'re** not nearly moved to tears **by** **a** couple **of** scenes , you **'ve** got **ice** water **in** your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 199 Iter 17000 loss=-1564.0931 elbo 1440.0422 ll -153.1455 kl 0.2651 sf 1593.4528 selected 0.3024\n",
      "\n",
      "# epoch 199 iter 17000: dev loss -1569.3447 elbo 1569.3447 ll -146.7211 kl 0.0810 sf 1716.1469 selected 0.2958 acc 0.3624\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with **lovely** **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** which **is** probably **for** **the** best .\n",
      " dev2 [gold=3,pred=3]: **and** if you 're not **nearly** **moved** to tears by a couple **of** scenes , you 've got ice water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "\n",
      "# epoch 200 iter 17085: dev loss -1577.6670 elbo 1577.6670 ll -146.1817 kl 0.4337 sf 1724.2823 selected 0.3004 acc 0.3524\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** lovely film with lovely performances by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here **,** **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: and **if** **you** **'re** not nearly moved to tears by a **couple** of **scenes** **,** you 've got ice water in **your** veins **.**\n",
      "\n",
      "Epoch 201 Iter 17100 loss=-1553.5463 elbo 1664.9655 ll -147.2853 kl 0.4137 sf 1812.6646 selected 0.2985\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w_Ko657vRGo"
   },
   "source": [
    "# Variance reduction\n",
    "\n",
    "**This is an extra**\n",
    "\n",
    "We can use a *control variate* to reduce the variance of our gradient estimates.\n",
    "\n",
    "Let's recap the idea in general terms. We are looking to solve some expectation\n",
    "\\begin{align}\n",
    "\\mu_f = \\mathbb E[f(Z)]\n",
    "\\end{align}\n",
    "but unfortunatelly, realising the full sum (or integral for continuous variables) is intractable. Thus we employ MC estimation\n",
    "\\begin{align}\n",
    "\\hat \\mu_f &\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S f(z_s) & \\text{where }z_s \\sim Q(z|x)\n",
    "\\end{align}\n",
    "Note that the variance of this estimate is\n",
    "\\begin{align}\n",
    "\\text{Var}(\\hat \\mu_f) &=  \\frac{1}{S}\\text{Var}(f(Z)) \\\\\n",
    "&= \\frac{1}{S} \\mathbb E[( f(Z) - \\mathbb E[f(Z)])^2]\n",
    "\\end{align}\n",
    "Note that this variance is such that it goes down as we sample more, in a rate $\\mathcal O(S^{-1})$.\n",
    "See that if we sample $10$ times more, we will only obtain an decrease in variance in the order of $10^{-1}$. This means that sampling more is generally not the most convenient way to decrease variance.\n",
    "\n",
    "*Digression* we can estimate the variance itself via MC, an unbiased estimate looks like\n",
    "\\begin{align}\n",
    "\\hat \\sigma^2_f = \\frac{1}{S(S-1)} \\sum_{s=1}^S (f(z_s) - \\hat \\mu_f)^2\n",
    "\\end{align}\n",
    "but not that this estimate is even hard to improve since it decreases with $\\mathcal O(S^{-2})$.\n",
    "\n",
    "Back to out main problem: let's try and improve the variance of our estimator to $\\mu_f$.\n",
    "\n",
    "It's a fact, and it can be shown trivially, that\n",
    "\\begin{align}\n",
    "\\mu_f &=  \\mathbb E[f(Z) - \\psi(Z)] + \\underbrace{\\mathbb E[\\psi(Z)]}_{\\mu_\\psi} \\\\\n",
    " &\\overset{\\text{MC}}{\\approx} \\underbrace{\\left(\\frac{1}{S} \\sum_{s=1}^S f(z_s) - \\psi(z_s) \\right) + \\mu_\\psi}_{\\hat c}\n",
    "\\end{align}\n",
    "where we assume the existence of some function $\\psi(z)$ for which the expected value $\\mu_\\psi$ is known and we estimate the expected difference $\\mathbb E[f(Z) - \\psi(Z)]$ via MC. We used this axuxiliary function, also known as a *control variate*, to derive a new estimator, which we will denote by $\\hat c$.\n",
    "\n",
    "The variance of this new estimator is show below:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}( \\hat c ) &= \\text{Var}(\\hat \\mu_{f-\\psi}) + 2\\underbrace{\\text{Cov}(\\hat \\mu_{f-\\psi}, \\mu_\\psi)}_{\\mathbb E[\\hat \\mu_{f-\\psi}  \\mu_\\psi] - \\mathbb E[\\hat \\mu_{f-\\psi}] \\mathbb E[\\mu_\\psi]} + \\underbrace{\\text{Var}(\\mu_\\psi)}_{\\color{blue}{0} } \\\\\n",
    "&= \\frac{1}{S}\\text{Var}(f- \\psi)  + 2 \\underbrace{\\left( \\mu_\\psi \\mu_{f-\\psi} - \\mu_{f-\\psi} \\mu_\\psi \\right)}_{\\color{blue}{0}} \n",
    "\\end{align}\n",
    "where the variance of $\\mu_\\psi$ is 0 because we know it in closed form (no need for MC estimation), and the covariance is $0$ as shown in the second row.\n",
    "\n",
    "That is, the variance of $\\hat c$ is essentially the variance of estimating $\\mathbb E[f(Z) - \\psi(Z)]$, which in turn depends on the variance \n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}(f-\\psi) &= \\text{Var}(f) - 2\\text{Cov}(f, \\psi) + \\text{Var}(\\psi)\n",
    "\\end{align}\n",
    "where we can see that if $\\text{Cov}(f, \\psi) > \\frac{\\text{Var}(\\psi)}{2}$ we achieve variance reduction as then $\\text{Var}(f-\\psi)$ would be smaller than $\\text{Var(f)}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovKcRnqH_PGp"
   },
   "source": [
    "\n",
    "## Baselines\n",
    "\n",
    "Baslines are control variates of a very simple form:\n",
    "\\begin{align}\n",
    "\\mathbb E[f(Z)] = \\mathbb E[f(Z) - C] + \\mathbb E[C]\n",
    "\\end{align}\n",
    "where $C$ is a constant with respect to $z$.\n",
    "\n",
    "In the context of the score function estimator, a baseline looks like a quantity $C(x; \\omega)$, this may be\n",
    "* just a constant;\n",
    "* or a function of the input (but not of the latent variable), which could be itself implemented as a neural network;\n",
    "* a combination of the two.\n",
    " \n",
    "\n",
    "Let's focus on the first term of the ELBO (so I'm omitting the KL term here). The gradient with respect to parameters of the inference model becomes:\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\\\\\n",
    "&=\\mathbb E_{Q(z|x, \\lambda)}\\left[\\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) - \\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] + \\underbrace{\\mathbb E_{Q(z|x, \\lambda)}\\left[\\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] }_{=0} \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\color{blue}{\\left(\\log P(x|z, \\theta) - C(x; \\omega) \\right)}\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right] \\\\\n",
    "&\n",
    "\\end{align}\n",
    "We can show that the last term is $0$\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]  \\\\&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]\\\\\n",
    "&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\right] \\\\\n",
    "&= C(x; \\omega) \\sum_z Q(z|x, \\lambda) \\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\\\\n",
    "&= C(x; \\omega) \\sum_z\\nabla_\\lambda Q(z|x, \\lambda)  \\\\\n",
    "&= C(x; \\omega) \\nabla_\\lambda \\underbrace{\\sum_z Q(z|x, \\lambda)  }_{=1}\\\\\n",
    "&=0\n",
    "\\end{align}\n",
    "\n",
    "Examples of useful baselines:\n",
    "\n",
    "* a running average of the learning signal: at some iteration $t$ we can use a running average of $\\log P(x|z, \\theta)$ using parameter estimates $\\theta$ from iterations $i < t$, this is a baseline that likely leads to high correlation between control variate and learning signal and can lead to variance reduction;\n",
    "* another technique is to have an MLP with parameters $\\omega$ predict a scalar and train this MLP to approximate the learning signal $\\log P(x|z, \\theta)$ via regression:\n",
    "\\begin{align}\n",
    "\\arg\\max_\\omega \\left( C(x; \\omega) - \\log P(x|z, \\theta) \\right)^2\n",
    "\\end{align}\n",
    "its left as an extra to implement these ideas.\n",
    "\n",
    "One more note: we can also use something called a *multiplicative baseline* in the literature of reinforcement learning, whereby we incorporate a running estimate of the standard deviation of the learning signal computed based on the values attained on previous iterations:\n",
    "\\begin{align}\n",
    "\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\frac{1}{\\hat\\sigma_{\\text{past}}}\\left(\\log P(x|z, \\theta) - \\hat \\mu_{\\text{past}}\\right)\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\n",
    "\\end{align}\n",
    "this form of contorl variate aim at promoting the learning signal (or reward in reinforcement learning literature) to be distributed by $\\mathcal N(0, 1)$. Note that multiplying the reward by a constant does not bias the estimator, and in this case, may lead to variance reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVsWgmlIWvZq"
   },
   "outputs": [],
   "source": [
    "a = torch.ByteTensor([1])\n",
    "b = torch.FloatTensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2VntYV3WvZt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b * a.type(b.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTxG1AvPWvZv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
